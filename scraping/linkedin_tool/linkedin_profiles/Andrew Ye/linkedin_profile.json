[
  {
    "fullName": "Andrew Ye",
    "linkedin_internal_id": "1029350552",
    "first_name": "Andrew",
    "last_name": "Ye",
    "public_identifier": "andrewye1",
    "background_cover_image_url": "https://static.licdn.com/aero-v1/sc/h/5q92mjc5c51bjlwaj3rs9aa82",
    "profile_photo": "https://static.licdn.com/aero-v1/sc/h/9c8pery4andzj6ohjkjp54ma2",
    "headline": "Student at Stanford University",
    "location": "321 followers\n          \n          \n              318 connections",
    "about": "",
    "experience": [
      {
        "position": "Undergraduate Researcher",
        "company_url": "https://www.linkedin.com/company/case-school-of-engineering-at-case-western-reserve-university?trk=public_profile_experience-item_profile-section-card_subtitle-click",
        "company_name": "Case School of Engineering at Case Western Reserve University",
        "location": "Cleveland, Ohio, United States",
        "summary": "Dr. Shuai Xu, Dr. Vipin Chaudhary, Rice DATA lab; NeurIPS 2023, ICML 2024andrew-ye.com/publications",
        "starts_at": "Jun 2023",
        "ends_at": "Present",
        "duration": "1 year 10 months"
      },
      {
        "position": "Visiting Instructor",
        "company_url": "https://www.linkedin.com/school/digipen-institute-of-technology/?trk=public_profile_experience-item_profile-section-card_subtitle-click",
        "company_name": "DigiPen Institute of Technology",
        "location": "Redmond, Washington, United States",
        "summary": "Data Analytics and Statistics",
        "starts_at": "Jun 2024",
        "ends_at": "Jul 2024",
        "duration": "2 months"
      },
      {
        "position": "Teaching Assistant",
        "company_url": "https://www.linkedin.com/school/case-western-reserve-university/?trk=public_profile_experience-item_profile-section-card_subtitle-click",
        "company_image": "https://media.licdn.com/dms/image/v2/D4E0BAQHPwBDBTA9tvA/company-logo_100_100/company-logo_100_100/0/1713131155807/case_western_reserve_university_logo?e=2147483647&v=beta&t=N1GbalcdtNpI8v8qAKkUgt9R3gBwPA5XhMaLsojRe1g",
        "company_name": "Case Western Reserve University",
        "location": "Cleveland, Ohio, United States",
        "summary": "Algorithms, Discrete Mathematics",
        "starts_at": "Aug 2023",
        "ends_at": "May 2024",
        "duration": "10 months"
      },
      {
        "position": "Software Engineering Intern",
        "company_url": "https://www.linkedin.com/company/zventus?trk=public_profile_experience-item_profile-section-card_subtitle-click",
        "company_image": "https://media.licdn.com/dms/image/v2/C560BAQFYPhL0a9ykUg/company-logo_100_100/company-logo_100_100/0/1630620539943/zventus_logo?e=2147483647&v=beta&t=Trs1D8RMP-3CeMuSpYGAXe5kS7MylAJuhBjk3MkG_9Q",
        "company_name": "Zventus",
        "location": "Los Angeles, California, United States",
        "summary": "Healthcare technologies",
        "starts_at": "May 2023",
        "ends_at": "Aug 2023",
        "duration": "4 months"
      }
    ],
    "education": [
      {
        "college_url": "https://www.linkedin.com/school/stanford-university/?trk=public_profile_school_profile-section-card_image-click",
        "college_name": "Stanford University",
        "college_image": "https://media.licdn.com/dms/image/v2/C560BAQHr9suxyJBXMw/company-logo_100_100/company-logo_100_100/0/1635534378870/stanford_university_logo?e=2147483647&v=beta&t=ZvB25L95o9w4q9drvsWxGcM49tX66Cf5LsLAxYp8rSs",
        "college_degree": "B.S.",
        "college_degree_field": "Mathematics and Computer Science",
        "college_duration": "2024 - 2026",
        "college_activity": ""
      },
      {
        "college_url": "https://www.linkedin.com/school/case-western-reserve-university/?trk=public_profile_school_profile-section-card_image-click",
        "college_name": "Case Western Reserve University",
        "college_image": "https://media.licdn.com/dms/image/v2/D4E0BAQHPwBDBTA9tvA/company-logo_100_100/company-logo_100_100/0/1713131155807/case_western_reserve_university_logo?e=2147483647&v=beta&t=N1GbalcdtNpI8v8qAKkUgt9R3gBwPA5XhMaLsojRe1g",
        "college_degree": "B.S.",
        "college_degree_field": "Mathematics and Computer Science",
        "college_duration": "2022 - 2024",
        "college_activity": "Transferred fall \u201824"
      }
    ],
    "articles": [],
    "description": {
      "description1": "Case School of Engineering at Case Western Reserve University",
      "description1_link": "https://www.linkedin.com/company/case-school-of-engineering-at-case-western-reserve-university?trk=public_profile_topcard-current-company",
      "description2": "Stanford University",
      "description2_link": "https://www.linkedin.com/school/stanford-university/?trk=public_profile_topcard-school",
      "description3": "Personal Website",
      "description3_link": "https://www.linkedin.com/redir/redirect?url=andrew-ye%2Ecom&urlhash=ITY3&trk=public_profile_topcard-website"
    },
    "activities": [],
    "volunteering": [
      {
        "company_url": "https://www.linkedin.com/company/north-helpline?trk=public_profile_volunteering-position_profile-section-card_image-click",
        "company_position": "Volunteer",
        "company_name": "North Helpline",
        "company_duration": "",
        "starts_at": "May 2021",
        "ends_at": "Apr 2022"
      }
    ],
    "certification": [],
    "people_also_viewed": [
      {
        "link": "https://www.linkedin.com/in/varungoyal23?trk=public_profile_relatedPosts_face-pile-cta",
        "name": "",
        "summary": "Varun Goyal\n        \n              \n          \ud83c\udf1f \ud835\udc03\ud835\udc2b\ud835\udc1e\ud835\udc1a\ud835\udc26\ud835\udc22\ud835\udc27\ud835\udc20 \ud835\udc01\ud835\udc22\ud835\udc20, \ud835\udc01\ud835\udc2e\ud835\udc22\ud835\udc25\ud835\udc1d\ud835\udc22\ud835\udc27\ud835\udc20 \ud835\udc01\ud835\udc22\ud835\udc20\ud835\udc20\ud835\udc1e\ud835\udc2b \ud83c\udf1f\n\nLast May, I embarked on an incredible journey with WisdomAI right after graduating from UIUC, and it has been nothing short of a dream run! Starting my career with a passionate, dynamic team like this one has been an amazing experience. \ud83d\ude80\n\nHere\u2019s what I\u2019ve absolutely loved about my time at WisdomAI so far:\n\n1\ufe0f\u20e3 Ownership Sparks Passion\nWhen you\u2019re empowered with the right motivation and a sense of ownership, the task transforms into a pursuit. I\u2019ve cherished the freedom to take charge of my projects, driven by curiosity for achieving results rather than just deadlines.\n\n2\ufe0f\u20e3 Culture of Growth & Impact\nI\u2019m deeply grateful to the founders and my team for cultivating an environment of insane growth while delivering great value to our customers every single day. Huge thanks to the founders - Soham, Sharvanath, Kapil, and Guilherme for fostering this environment.\n\n3\ufe0f\u20e3 The Power of Team Energy\nThe motivation and drive of the people around you can make all the difference. Being surrounded by such an energetic, supportive team has truly set the trajectory for my career. \n\nAs we step into this new year, we\u2019re doubling down with more energy, sharper focus, and even bigger goals for our startup. Here\u2019s to a year of innovation, impact, and scaling new heights together! \ud83d\udca1\ud83c\udf0d\n\n\n\n#StartupJourney #GrowthMindset #WisdomAI #Teamwork #Innovation #NewYearGoals #CareerJourney",
        "location": "136\n              \n            \n      \n  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n            \n      \n        \n                7 Comments"
      },
      {
        "link": "https://www.linkedin.com/in/prakhar-sinha-57a412201?trk=public_profile_relatedPosts_face-pile-cta",
        "name": "",
        "summary": "Prakhar Sinha\n        \n              \n          A few short days ago, I wrapped up my research position at UC Davis Health with Professor Farzad Fereidouni. My role at the lab entailed a specialization in machine learning and computer vision and I'm excited to share what I was able to accomplish with everyone. \n\nI worked on two projects during my time at the lab. The first one was something I called \"Kernel Generation for Image Similarity\" (https://lnkd.in/ghsY73ts). It was to process an image such that it would look like it was H&E stained. I learned a lot about the basics of histology and digital histology through this process. The most novel part of this approach was using Wiener deconvolution to generate a kernel that would be used to enhance image similarity (typically using SSIM, MSE or a combination of both). \n\nA big part of this process was optimization. I learned how to use Python libraries such as Cupy and other tools to GPU accelerate a lot of these image-processing optimization problems.\n\nMy second project and my most meaningful contribution was called \"FastSAM-needle-biopsy\" (https://lnkd.in/gXXydq-X). The objective of this project was to use the FastSAM image segmentation network to accurately generate image segmentation masks of live tissue such that a microscope would only scan the relevant parts of an image. Here is step by step walkthrough of the image processing pipeline:\n\n1) VB.NET (Darius) application calls a DLL (compiled from csharp.NET)\n2) DLL calls FastSAM image segmentation code using Python.NET\n3) FastSAM segments image and returns image segmentation bitmask and as well as the fastest path to visit every bit (Traveling Salesman Problem)\n4) Python returns values are returned to DLL using JSON as a reliable data transfer solution\u00a0\n5) DLL returns an object that can be parsed by VB.NET\n\nFastSAM is a faster version of Meta Research's Segment Anything Model and I used it to greatly speed up development time on this project. It was a big challenge to integrate such cutting-edge, machine-learning driven, image processing pipelines into a legacy codebase that was written in Visual Basic .NET but thanks to tools such as DLLs, JSON, and C#, I was able to figure it out!\n\nI am very grateful for the time I spent in the lab. I feel like I developed some great programming skills, especially in computer vision, that will prove useful for the rest of my career. I'd like to give special thanks to Professor Fereidouni, Ruby Mascareno, Willy Ju, Dena Sayrafi, Ruben Gnanaruban, Inyola, Antara Mallick, and Jayla. \n\nThe link is here if you'd like to see my lab report going over everything I did in more technical detail and with a few pictures!\n\nhttps://lnkd.in/gRpZVmjG\n\n#computervision #machinelearning #AI #histology",
        "location": "67\n              \n            \n      \n  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n            \n      \n        \n                10 Comments"
      },
      {
        "link": "https://www.linkedin.com/in/anupriyadixit123?trk=public_profile_relatedPosts_face-pile-cta",
        "name": "",
        "summary": "Anupriya Dixit\n        \n              \n          \ud83c\udf1f Today marks the end of the first week of the Headstarter AI Fellowship, and I\u2019m thrilled to share my accomplishments and experiences:\n\n\ud83c\udf10 Created and Deployed a Personal Website: Launched my personal website using GitHub Pages. \nCheck it out here: https://lnkd.in/eeKrm26H\n\n\ud83e\udd1d Collaborative Team Meetings: Met with my amazing team, Lawrence Hoerst and America Gaona Borges, to brainstorm final project ideas aiming to attract 1,000 users by the end of these 7 weeks.\n\n\ud83e\udd16 AI Mock Interview: Completed a mock interview with an AI interviewer and received valuable feedback on my skills.\n\n\ud83d\udd17 Networking: Connected with Software Engineers on LinkedIn by reaching out and expanding my professional network.\n\n\ud83c\udfa4Entrepreneurship Insights: Attended a panel session on Thursday with incredible speakers:\u00a0 Nabeel Alamgir\ud83e\udd84,  Logan Havern, Dustin Beadle, Shariar Kabir, Miguel Acero, who shared their insights on entrepreneurship and generating users for our projects. One of my key takeaways from this event has been the concept of \u201cfailing gracefully.\u201d Failure is not an end but a stepping stone to success. Embracing setbacks with resilience and learning from them is crucial in our growth journey.\n\n\n\ud83d\udde3\ufe0f Peer Feedback: Provided constructive feedback on peers\u2019 projects.\n\nAdditionally, I gained so much more by attending the daily sessions and today's hackathon demo. There are so many exciting projects to look forward to. A special shout-out to the hackathon winners of the projects: CitySwipe, iBudget and react-form-validator-mini,\u00a0 who completed their projects in just 36 hours and generated over 500 users!\n\nAlthough I couldn\u2019t participate in this week\u2019s hackathon due to other commitments, I\u2019m eagerly looking forward to joining next week!\n\n\n\ud83c\udf1f Next Steps: I\u2019m excited to have my personal website up and running, showcasing all my projects. My next step is to buy a domain and connect it to my website. Starting tomorrow, I\u2019ll be diving into Project 2: Pantry Tracker, utilizing React.js, Next.js, and Firebase.\n\nI am immensely grateful to Yasin Ehsan \ud83d\ude80 and his team for providing budding software engineers like myself with such a valuable opportunity. Not only am I expanding my skill set, but I\u2019m also learning how to build my personal brand and market myself as a software engineer.",
        "location": "18\n              \n            \n      \n  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n            \n      \n        \n                1 Comment"
      },
      {
        "link": "https://www.linkedin.com/in/vivan-gupta-b63835264?trk=public_profile_relatedPosts_face-pile-cta",
        "name": "",
        "summary": "Vivan Gupta\n        \n              \n          This past weekend, I had the amazing opportunity to build out a new idea at the Berkeley AI Hackathon. It was a great time, and I learned a lot from the experience. Our team built Billy, a social media platform to help people engage more thoughtfully within the political sphere by helping make their ideas for bills come to life. Thanks for having me and thanks to my team for helping building such a cool platform!\n\nBilly's goal is to foster informed political engagement online. Using AI and a vast database of American legislation, users can write their bills. Once a bill is created with Billy, it's posted for others to interact with\u2014exploring ideas, voting on issues, and leaving comments. Billy promotes thoughtful dialogue, new perspectives, and idea-sharing, creating a space for public political discussion.\n\nTo learn more about how we built it, feel free to check out this dev post. Also, check out our demo in this video.\n\nhttps://lnkd.in/e3Um8SGf\nhttps://lnkd.in/eGueJYAe\n\n#AI #Hackathon #BerkeleyAI #PoliticalEngagement #CivicTech #Innovation #MachineLearning #WebDevelopment #Nextjs #OpenAI",
        "location": "36\n              \n            \n      \n  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n            \n      \n        \n                3 Comments"
      },
      {
        "link": "https://ae.linkedin.com/in/mmaaz60?trk=public_profile_relatedPosts_face-pile-cta",
        "name": "",
        "summary": "Muhammad Maaz\n        \n              \n          Knock knock! \ud83d\udeaa Who's there? \ud83e\udd14 It's GLaMM! \ud83c\udf1f\n\nExcited to share that our paper, GLaMM: Pixel Grounding Large Multimodal Model, will be presented at CVPR 2024! \ud83c\udf89\ud83c\udf89  tomorrow (Jun 20, 2024, Thursday) at 10:30 AM, poster #326! \ud83d\udd25\n\nWhy GLaMM is special \ud83d\ude4c:\n\n1. First end-to-end LMM tackling multiple vision-language tasks like Grounded Conversation Generation (GCG), image captioning, region-captioning, referring expressions segmentation, visual question answering, and more in a single model. \ud83d\udca5\n\n2. We developed a fully automatic image annotation pipeline to build GranD dataset. \ud83d\udcca\u2728\n\n3. Fully open-source: Code, models, dataset, and dataset generation pipeline. \ud83d\ude80\ud83d\udcbb\n\nCheck it out:\nGranD Dataset: https://lnkd.in/eYuKia9C\nGranD-f Dataset: https://lnkd.in/dYcjC_e8\nCode: https://lnkd.in/d3yFnPRt (Do not forget to \u2b50\ufe0f our repo).\n\nCome meet the team (Hanoona, Sahal, Salman, Ming-Hsuan, Fahad) at Arch4A-E at poster #326 to know more! \ud83d\ude0a\ud83d\udc69\u200d\ud83d\udcbb\ud83d\udc68\u200d\ud83d\udcbb\n\n#CVPR2024 #MultimodalModels #VisionLanguage",
        "location": "147\n              \n            \n      \n  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n            \n      \n        \n                4 Comments"
      },
      {
        "link": "https://in.linkedin.com/in/raj-abhijit-dandekar-67a33118a?trk=public_profile_relatedPosts_face-pile-cta",
        "name": "",
        "summary": "Raj Abhijit Dandekar\n        \n              \n          What society values may not be the best thing for you.\n\nWhen I applied for grad school, I got admits from MIT, Stanford, Purdue, CMU and UIUC.\n\nI knew I wanted to do a PhD.\u00a0I chose MIT immediately, because it was ranked number 1. \n\nI never thought whether it was a good decision or not. \n\nI just assumed that it\u2019s a good decision because it\u2019s rated higher than the other universities.\n\nWhen I joined MIT, all that rank 1 noise disappeared.\n\nAll I was surrounded by was my lab, my lab group members and my advisor. \n\nI had never carefully considered whether this research group was a good fit for me. I just joined the first MIT research group which came my way.\n\nThis led to a miserable first 2 years of PhD for me. \n\nThe group was not a good fit and the research topic was also not a good fit.\n\nThese lost 2 years were a result of choosing what society values more (university ranking) rather than what is a better thing for me.\n\nWhen I look back, I should have done the following:\n\n(1) I should have made a list of all research groups I was interested in, from all universities I was selected to.\n\n(2) I should have spoken with the lab advisor from all these research groups and understood their vision.\n\n(3) I should have learnt more about the group culture by talking to past members of the group. Graduating members are usually very honest. They would tell you if the culture is toxic, if the advisor is micromanaging etc.\n\n(4) I should have looked at the group website to look at the publication rate, what do the alumni end up doing etc? If the average graduation time is 8 years, it\u2019s a red flag.\n\nAfter doing the above 4 things, I should have selected the best research group for me.\n\nI should have selected the research group whose culture aligns well with my personality.\n\nSociety values ranking. \n\nHowever, when you enter the university for a PhD, the ranking does not matter. Your research group matters. What you do every day after waking up matters.\n\nAnd if you blindly select universities based on the ranking, the research group won\u2019t be a good fit and it would lead to a terrible PhD experience.\n\nIt turns out that society misguides people in many other professions including:\n\n- Choosing to prepare for IIT-JEE just because society prefers that you are an IITian\n- Choosing a job just because society prefers higher salary\n- Choosing to not do a startup because the society (your parents) don\u2019t approve\n\nAlways question yourself before blindly making decisions based on what the society values. It might not be the best thing for you.\n\nGoing against traditional societal values is hard in the short term, but it pays off in the long run.\n\nP.S: In the photo, you can see me during my first day at MIT!",
        "location": "308\n              \n            \n      \n  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n            \n      \n        \n                6 Comments"
      },
      {
        "link": "https://in.linkedin.com/in/vidhi-shukla-377268245?trk=public_profile_relatedPosts_face-pile-cta",
        "name": "",
        "summary": "Vidhi Shukla\n        \n              \n          \ud83c\udf1f Thrilled to Announce Our Latest Research! \ud83c\udf1f\n\nI am excited to share our recently published paper, \"Advancing Prenatal Diagnostics: A Novel Approach Using Machine Learning to Assess Fetal Well-being,\" in the February 2024 issue of TIJER. This groundbreaking research introduces a robust ML-driven framework for the early detection and prediction of fetal health issues, utilizing cardiotocographic data.\n\nIn this study, I took a leading role in developing the methodology and analyzing the data, employing sophisticated machine learning algorithms such as SVM, Random Forest, KNN, LVQ, and advanced ensemble models including XGBoost, AdaBoost, and LightGBM. These tools have significantly surpassed traditional monitoring techniques in predicting fetal health, offering deeper insights and potential for early intervention.\n\nI am deeply grateful for the guidance and mentorship of Dr. Santosh Kumar Singh  and Rimsy Dua, whose profound insights and support have been instrumental in shaping this research. This achievement also wouldn't have been possible without the immense collaboration from my fellow researcher, Pranav K., whose expertise in machine learning greatly enriched our work and findings.\n\nRead the full paper here to discover how we are pushing the boundaries of prenatal care through technology.\nhttps://lnkd.in/dK7CvgVb\n\n#MachineLearning  #PrenatalCare #HealthcareInnovation #ResearchPublication\n#DataScience #HealthTech #AIinHealthcare #MedicalResearch #DigitalHealth #PregnancyCare #WomenInSTEM #TechForGood #PublicHealth",
        "location": "22\n              \n            \n      \n  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n            \n      \n        \n                2 Comments"
      },
      {
        "link": "https://www.linkedin.com/in/josh-chang11?trk=public_profile_relatedPosts_face-pile-cta",
        "name": "",
        "summary": "Josh Chang\n        \n              \n          \ud83c\udf09 Dead Week at UC Berkeley \ud83c\udf09\nMay has swept through Berkeley, bringing with it the annual tradition known as Dead Week. As the buzz of Telegraph Avenue dims slightly, we undergrads know it\u2019s our cue to hunker down and hit the books one last time before finals. Here are some key points I've been focusing on as we wrap up this dead week!\n\nLesson 1: Structure in Chaos\nBerkeley\u2019s Dead Week is ironically alive with a flurry of review sessions and last-minute project deadlines. I've found that a structured approach\u2014breaking down study sessions into focused blocks\u2014helps me navigate this intense week. The serene backdrop of the Bay Area, from the calming waters by the marina to the redwoods around campus, provides the perfect study break scenery to clear my mind and reset.\n\nLesson 2: The Strength of Shared Struggles\nThere's something about the communal silence of Mainstacks Library during Dead Week that reminds you you're not alone. Joining forces with other students, we grind out practice exams and Pomodoro sessions until 2 am. It's these moments of collaboration that transform challenging content into shared victories.\n\nLesson 3: Well-being as a Priority\nDead Week at Berkeley is not just about academic survival but also about maintaining well-being amidst the madness. I make it a point to keep up with my runs through the Fire Trails, ensuring that my mental and physical health aren\u2019t sidelined during these critical times.\n\nLesson 4: Reflection and Readiness\nAs I review notes and practice problems, I\u2019m also reflecting on how each semester builds more than just technical skills. It hones resilience, deepens patience, and expands my understanding of what I can achieve under pressure.\n\nWith finals on the horizon, I feel prepared and eager to tackle the challenges ahead. To my peers also in the midst of Dead Week, let\u2019s push through to the finish line with determination and spirit! \ud83d\udcaa\n\nWhat are your Dead Week strategies? Let\u2019s share some wisdom and encouragement as we gear up for finals! \ud83d\ude80 #UCBerkeley #ComputerScience #DeadWeek #FinalsPreparation #GoBears",
        "location": "39\n              \n            \n      \n  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n            \n      \n        \n                6 Comments"
      },
      {
        "link": "https://www.linkedin.com/in/trenton-chang?trk=public_profile_relatedPosts_face-pile-cta",
        "name": "",
        "summary": "Trenton Chang\n        \n              \n          Very excited to announce our new study on biases in laboratory testing & implications for machine learning (ML) in healthcare, appearing in PLOS Global Public Health! Read more from Michigan Engineering News: https://lnkd.in/gd-_DA7r\n\nIn summary: we observed differences in laboratory testing rates between Black and White patients in emergency departments in two large U.S. teaching hospitals: a Black patient of the same age, biological sex and reason for visit as a White patient was significantly less likely to receive common tests.\n\nWhat does this mean for ML? Diagnostic/lab test results are often used as labels to train ML models for various clinical tasks. Our findings raise concerns that AI models could inadvertently amplify existing biases in the delivery of clinical care. \n\nThroughout my PhD, I've studied this source of bias from a theoretical + ML modeling perspective. But we now have evidence that this type of bias exists in practice. \n\nTo end on an uplifting note \u2014 I hope my line of work can give researchers in ML + healthcare an angle to think about how to develop more equitable models, grounded in a real-world source of bias that likely pervades clinical datasets.\n\nThis was joint work with my collaborators at Michigan Medicine, Michigan AI Lab and the Ann Arbor VA. Read our study here: https://lnkd.in/g6qjkbgD",
        "location": "30"
      },
      {
        "link": "https://www.linkedin.com/in/denisse-damian/en?trk=public_profile_relatedPosts_face-pile-cta",
        "name": "",
        "summary": "Denisse Damian \ud83d\udc69\u200d\ud83d\udcbb\n        \n              \n          To all my friends currently interviewing for Software Engineer positions  \n\n\nHere are some tips on how to \ud83d\udd28  it    \n\n1. Master the basics. Don\u2019t overcomplicate things. Unless you\u2019re up against a particularly challenging interviewer, you\u2019ll likely encounter a LeetCode Medium question.\n\n2. Create a solid study plan. Compile a list of LeetCode problems to tackle\u2014aim for 75 Blind or follow my curated list of problems, ranging from easy to medium. (DM me or drop a comment) \n\n3. Be mindful of your communication. Avoid talking just for the sake of it, match your interviewer's \u2728 vibes \u2728",
        "location": "15"
      },
      {
        "link": "https://www.linkedin.com/in/denisse-damian/en?trk=public_profile_relatedPosts_face-pile-cta",
        "name": "",
        "summary": "Denisse Damian \ud83d\udc69\u200d\ud83d\udcbb\n        \n              \n          To all my friends currently interviewing for Software Engineer positions \n\n\nHere are some tips on how to \ud83d\udd28 it \n\n1. Master the basics. Don\u2019t overcomplicate things. Unless you\u2019re up against a particularly challenging interviewer, you\u2019ll likely encounter a LeetCode Medium question.\n\n2. Create a solid study plan. Compile a list of LeetCode problems to tackle\u2014aim for 75 Blind or follow my curated list of problems, ranging from easy to medium. (DM me or drop a comment) \n\n3. Be mindful of your communication. Avoid talking just for the sake of it, match your interviewer's \u2728 vibes \u2728",
        "location": "4"
      },
      {
        "link": "https://www.linkedin.com/in/david-hollinger1?trk=public_profile_relatedPosts_face-pile-cta",
        "name": "",
        "summary": "David Hollinger\n        \n              \n          I\u2019m thrilled to share that my \ud835\udde7\ud835\udddb\ud835\udddc\ud835\udde5\ud835\uddd7 first-author paper, \"A Hierarchical-Based Learning Approach for Multi-Action Intent Recognition\" was recently accepted for publication! \u270d \ud83c\udf89 \n\nPersonally, this paper was my favorite among a collection of studies in my dissertation, \"The Role of Artificial Intelligence for Human Intent Prediction Across Dynamic Actions Using Wearable Sensors.\"\n\n\ud83c\udf0d \ud835\udddb\ud835\uddf2\ud835\uddff\ud835\uddf2\u2019\ud835\ude00 \ud835\ude01\ud835\uddf5\ud835\uddf2 \ud835\uddef\ud835\uddf6\ud835\uddf4 \ud835\uddfd\ud835\uddf6\ud835\uddf0\ud835\ude01\ud835\ude02\ud835\uddff\ud835\uddf2: Predicting human motion based on the user's intent at the joint level has potential applications for wearable robotics, rehabilitation devices, and biomechanics research.\n\n\ud835\uddd5\ud835\uddee\ud835\uddf0\ud835\uddf8\ud835\uddf4\ud835\uddff\ud835\uddfc\ud835\ude02\ud835\uddfb\ud835\uddf1:\n\ud83d\udc49 Since the human motor system operates from general to specific, a hierarchical-based learning approach could result in a more effective control scheme.\n\ud83d\udc49 The findings of this novel approach could contribute to the field\u2019s understanding of how to optimize AI-based methods that mimic the human motor system to potentially integrate with exoskeletons.\n\n\ud835\udde0\ud835\uddf2\ud835\ude01\ud835\uddf5\ud835\uddfc\ud835\uddf1\ud835\ude00:\n\ud83d\udc49 We developed a novel hierarchical-based learning method that combines action classification (e.g., walking, running, kneeling) with joint-level predictions.\u00a0\n\ud83d\udc49 Explored action-generic vs. action-specific models for predicting joint angles at the ankle, knee, and hip.\n\ud83d\udc49 We trained deep learning and machine learning models on data collected from participants wearing inertial sensors.\n\n\ud835\udde5\ud835\uddf2\ud835\ude00\ud835\ude02\ud835\uddf9\ud835\ude01\ud835\ude00:\n\ud83d\udc49 Found that action-generic models trained on large, diverse datasets outperform hierarchical-based methods for multi-action scenarios.\n\n\ud835\uddde\ud835\uddf2\ud835\ude06 \ud835\udde7\ud835\uddee\ud835\uddf8\ud835\uddf2\ud835\uddee\ud835\ude04\ud835\uddee\ud835\ude06\ud835\ude00:\n\ud83d\udc49 Demonstrated the potential for IMU-driven, task-agnostic models to improve exoskeleton control and movement prediction accuracy.\n\ud83d\udc49 Enhancing human intent prediction across a wide range of tasks is essential for more robust and effective control of exoskeleton technology.\n\n\ud835\uddea\ud835\uddf5\ud835\uddee\ud835\ude01\u2019\ud835\ude00 \ud835\udde1\ud835\uddf2\ud835\ude05\ud835\ude01?\n\ud83d\udc49 We\u2019re calling for more diverse datasets incorporating cyclic and non-cyclic activities to make these systems even more robust and applicable.\u00a0\n\ud83e\uddbf \ud83d\udca1\u00a0The applications from this study range from improving the control of wearable robotics based on user intent to other biomechanics-related topics (e.g., sports performance and rehabilitation interventions).\n\n\ud83d\udc4f Huge s/o to co-authors: Michael Zabala Howard Chen Mark Schall Ryan Pollard\n\nLink to the full article in the comments.",
        "location": "44\n              \n            \n      \n  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n            \n      \n        \n                4 Comments"
      },
      {
        "link": "https://www.linkedin.com/in/patrick-halim?trk=public_profile_relatedPosts_face-pile-cta",
        "name": "",
        "summary": "Patrick Halim\n        \n              \n          We just made v1 of our app this weekend at the UC Berkeley AI Hackathon! \ud83d\udc68\u200d\ud83c\udf73 It's still very basic compared to the app we're envisioning, but it\u2019s a good start with one of our most important features (ai question asking) at a stage where we can actually try it out while cooking!\n\nOur app name is still TBD. Have any ideas??\n\n-\nWant to try it out? Join the waitlist: https://lnkd.in/gte54MYD\n\nAdhav Rajesh, Saif Alesawy, Nathan Yap \nbuildspace, Cal Hacks, Berkeley SkyDeck",
        "location": "79\n              \n            \n      \n  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n            \n      \n        \n                14 Comments"
      },
      {
        "link": "https://www.linkedin.com/in/langalibalele-lunga-160871278?trk=public_profile_relatedPosts_face-pile-cta",
        "name": "",
        "summary": "Langalibalele Lunga\n        \n              \n          Two summers ago, I got introduced to artificial intelligence during my sophomore year of high school. The exposure led me to pursue two summer internships at Oak Ridge National Laboratory(#ORNL), where I got to participate in a couple of exciting projects. Through the guidance of my mentors, our work led to research papers that have been presented at conferences. \n\nHere is a summary of the projects:\n\n\u2705 Project 1: \u201cHigh-Throughput Phenotyping using Computer Vision and Machine Learning\u201d\n\nThis collaborative project working with Vivaan Singhvi, Varrun Prakash, Pragya Nidhi, and Chris Keum\u00a0 resulted in a research paper submission to the Smoky Mountain Data Challenge 2023.\n\nOur project applied machine learning to conduct image analysis with the goal of enhancing high-throughput plant phenotype morphological classification. \n\nThe paper resulted in a Best Paper Award in the Undergraduate Division at Smoky Mountain Conference 2023 and was also presented at the American Geophysical Union (#AGU2024) in the high school division #BrightSTARS.\n\n\u27a1\ufe0f Link to paper: https://lnkd.in/ebM2286Q \n\n\u2705 Project 2: \u201cUndermining Classification Algorithms Using Adversarial Attacks\u201d\n\nThis project was conducted in the summer of 2023, my first summer internship at ORNL. In this research, we applied #GANs and #SMOTE to generate adversarial data for text classifiers and applied gradient-based attacks on #CNNs for facial recognition. The attacks caused a ~20% drop in text classification accuracy and a ~30% drop in facial recognition accuracy, underscoring the need for robust defense mechanisms for #CNN models. This project led to my first publication where I am the first author, and has been accepted at the Electronic Imaging Conference 2025.\n\n\u27a1\ufe0f Link to paper: https://lnkd.in/eTbXmurN \n\n\u2705 Project 3: \u201cAccelerating Scanning Probe Microscopy Using Sparse Reconstruction Techniques\u201d\n\nThis project was conducted during my summer internship in 2024. We focused on using Sparse Reconstruction techniques, such as image inpainting, to accelerate Scanning Probe Microscopy scans. My work focused on the algorithm that would be applied to the microscope using an #FPGA. I am currently working on a publication from this work.\n\nThank you to my mentors [Suhas Sreehari, Bashir Mohammed, PhD, Sarah Walters, Daniel S. Adams , Tyler Frazier , Singanallur Venkatakrishnan] for the excellent guidance and mentorship and to #ORNL and #ORISE for the opportunity to be part of the #NEXTGEN internship program.",
        "location": "51\n              \n            \n      \n  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n            \n      \n        \n                11 Comments"
      },
      {
        "link": "https://in.linkedin.com/in/mohammed-yousuf-1a7b3966?trk=public_profile_relatedPosts_face-pile-cta",
        "name": "",
        "summary": "mohammed yousuf\n        \n              \n           the article on robotics companies hiring:\n\n1. **Event and Background**: \n   - The author attended Automate in Chicago.\n   - They received positive feedback for TechCrunch's robotics job report.\n\n2. **Industry Insights**:\n   - The robotics industry has experienced fluctuations in funding and hiring.\n   - Despite these changes, it's an exciting time for the field.\n\n3. **Job Opportunities**:\n   - There are numerous job openings across various robotics categories.\n   - The industry is growing, with robotics impacting many aspects of life.\n\n4. **List of Companies Hiring**:\n   - The article lists 81 robotics companies with job openings.\n   - Examples include:\n     - **Advanced Construction Robotics** (1 role)\n     - **Aescape** (7 roles)\n     - **Ansys** (30 roles)\n     - **Aurora** (87 roles)\n     - **Berkshire Grey** (20 roles)\n     - **Gecko Robotics** (20 roles)\n     - **Outrider** (25 roles)\n     - **SeeGRID** (30 roles)\n\n5. **Industry Growth**:\n   - Robotics is expanding into new areas like humanoids and home robotics.\n   - The breadth of job categories reflects the industry's \nthe key points about the current state and job opportunities in the robotics industry.",
        "location": ""
      },
      {
        "link": "https://pk.linkedin.com/in/muhammad-ahmed-durrani?trk=public_profile_relatedPosts_face-pile-cta",
        "name": "",
        "summary": "Muhammad Ahmed\n        \n              \n          I am thrilled to announce that I have been selected as a Headstarter Software Engineering fellow at Headstarter AI. Over the next 5 weeks, I will be embarking on a journey to build 5 AI projects, culminating in a final project that I am incredibly excited about. \n\nDuring this fellowship, I am particularly looking forward to the opportunity to develop and showcase the following aspects:\n\n1) Vision: I am eager to hone my vision for leveraging AI in software engineering and its potential impact on various industries.\n\n2) Personal Brand: I aim to refine and strengthen my personal brand within the field of software engineering, showcasing my skills, expertise, and unique perspective.\n\n3) Interview Prep: I plan to use this time to enhance my interview preparation, ensuring that I am well-equipped to excel in technical interviews and articulate my ideas effectively.\n\n4) Network: Building a strong professional network is crucial in any field, and I am committed to expanding and nurturing my network within the software engineering community.\n\n5) Project: The opportunity to work on impactful AI projects will allow me to demonstrate my technical abilities and contribute to cutting-edge innovations.\n\n6) Teamwork/collaboration: I am eager to engage in collaborative efforts and learn from my peers, fostering a spirit of teamwork and mutual support. \n\n\nIf you have not applied, apply with my unique link https://lnkd.in/e9rRfKNn \n\n\n\nI want to THANKS Muhammad Usman & Imama Kainat for helping me, supporting me and being on my side in late night \"CODING ERRORS\". \ud83d\ude0a \n\n\n\n#Headstarter #SofftwareEngineering #ComputerScience\n #Aritificial_Intelligence",
        "location": "10\n              \n            \n      \n  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n            \n      \n        \n                7 Comments"
      },
      {
        "link": "https://in.linkedin.com/in/yashvi-sharma-150863220?trk=public_profile_relatedPosts_face-pile-cta",
        "name": "",
        "summary": "Yashvi S.\n        \n              \n          \ud83d\ude80 Introducing a Smart Pantry Management App with Image Capture and Firebase Integration! \ud83d\udcf8\ud83c\udf4e\n\nHi LinkedIn community! \ud83d\udc4b\nI'm excited to share a project I've been working on - a Pantry Management Application that simplifies keeping track of pantry items. This app features an intuitive image capturing capability and seamless integration with Firebase for storage and retrieval. This is my second-week project of Headstarter AI, and I'm thrilled to showcase what I've built so far.\n\nKey Features:\n\u2022 Add New Items: Capture or upload images of pantry items directly from your device.\n\u2022 Firebase Storage: Securely store item images in Firebase Storage and retrieve them effortlessly.\n\u2022 Real-time Updates: Track pantry items with real-time updates.\n\u2022 Search and Filter: Easily search and filter items by category or name.\n\u2022 Expiration Alerts: Get notified of upcoming expiration dates to minimize food waste.\n\nTechnologies Used:\n\u2022 React & Next.js: For building a responsive and dynamic user interface.\n\u2022 Firebase: For authentication, storage, and real-time database.\n\u2022 Material-UI: For sleek and accessible UI components.\n\u2022 Formidable: For handling file uploads seamlessly.\n\nHow It Works:\n\u2022 Capture Image: Use your device's camera to take a picture of the pantry item.\n\u2022 Upload Image: The captured image is uploaded to Firebase Storage.\n\u2022 Add Item: Fill in item details (name, quantity, expiration date, category) and add it to your pantry list.\n\u2022 Manage Pantry: View, edit, and delete items. See images and details at a glance.\n\nCheck out the GitHub repository for the complete code and setup instructions and dont forget to star it \u2b50: https://lnkd.in/gfQghFRq \ud83d\udcc2\n\nI'm thrilled to hear your feedback and suggestions! Feel free to connect with me for any questions or collaboration opportunities.\n\n#ReactJS #NextJS #Firebase #WebDevelopment #OpenSource #PantryApp #TechInnovation #HeadstarterAI",
        "location": "27\n              \n            \n      \n  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n            \n      \n        \n                3 Comments"
      },
      {
        "link": "https://www.linkedin.com/in/yuxuan-xue67?trk=public_profile_relatedPosts_face-pile-cta",
        "name": "",
        "summary": "Yuxuan (Iris) Xue\n        \n              \n          \ud83c\udf1f Thrilled to announce that I'll be working with Google as part of the Break Through Tech program at Cornell Tech this fall!\n\ud83c\udfaf Our project focuses on developing an innovative machine learning model designed to predict which YouTube videos are likely to go viral or trend. By analyzing early engagement metrics, video metadata, and external factors such as news events and social media trends, we'll aim to provide insights that can enhance YouTube's recommendation algorithms and help creators optimize their content strategy.\n\ud83d\udcbb Looking forward to contributing to a project that has the potential to significantly impact video discovery and content optimization on one of the world's most popular platforms!\n#Google #BreakThroughTech #MachineLearning #YouTube #AI #DataScience #CornellTech",
        "location": "100\n              \n            \n      \n  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n            \n      \n        \n                6 Comments"
      },
      {
        "link": "https://in.linkedin.com/in/anshuman-giramkar-b79783212?trk=public_profile_relatedPosts_face-pile-cta",
        "name": "",
        "summary": "Anshuman Giramkar\n        \n              \n          \ud83c\udf1f 2024: My Cookin' Story \ud83c\udf1f\n\nYou know, if I have to talk about something like a \"BEST YEAR\" for me, I have nothing as such. Every year would be similar\u2014I try at academics and career, I persevere for excellence, there are Victorious Moments, there are \"Where I went wrong?\" introspections, and so forth. One thought is frequent all the time at the end of every year: When will I transform into my \"PEAK\" version?\nThis was the year where I made no special resolutions or manifestations because I believed every year is the same or similar, with some \u00b1 level of subjective tolerance. I only promised to myself that I will accept whatever challenge comes my way and I will ace it without setting very high expectations. Why? Because I was still new to the professional world, fresh out of books & computers, and somewhere deep down, I wasn't fully aware of the war I was a part of.\n\nNow, looking back, I\u2019m glad about how far I\u2019ve come:\n\ud83d\udda5\ufe0f I got my 1st industrial-level internship as an SDE at PTC.\n\ud83d\ude80 Worked on a real software product application during my internship.\n\ud83d\udcdc My research paper publication count went from 2 to 5 in my final year of Computer Engineering (P.S. some papers are still to be indexed, but it's true... I promise).\n\ud83c\udf93 My 9+ CGPA respawned.\n\nIn addition to my professional achievements this year, I had the incredible opportunity to take a solo trip to London, UK \ud83c\uddec\ud83c\udde7\u2014a journey that added immense personal value to my life. During this trip, I learned valuable lessons on self-worth, presenting yourself confidently to the world, and managing your day effectively while navigating the challenges of being alone in an unfamiliar place. Networking with people across all walks of life gave me life lessons on discipline, career growth, and finding joy in the simple things.\n\nI learned that there is no \"Peak Version\" that happens all at once. I used to think that one day, a magical moment would come where I would transform into the perfect version of myself. But the truth? The \"Peak Anshuman\" I was waiting for isn't a destination\u2014it's a journey.\n\nEvery version of you that strives for excellence, where you\u2019re happy with your diurnal, content with your victories, and where you recognize and work on your weaknesses\u2014that\u2019s your \"Peak Version.\" Even when you cry after failure or regrets, but you fight back\u2014that\u2019s your peak. And when you let go of all pain and take lessons from it\u2014that\u2019s your peak.\nYour achievements and the highlights from a third-person eye, doesn\u2019t define your \"Peak\" it\u2019s the everyday\u2014the personal, professional, and mental growth you embody\u2014that defines how you live in your \"Peak\"\n\n\u2668\ufe0f That was my Cookin' Story. \u2668\ufe0f\n\nP.S. That's me at Lord's Stadium, where \ud83c\uddee\ud83c\uddf3 won it's First World Cup. \ud83d\udc93 \n\n \ud83c\udf89 Wish you all a very Happy 2025 in advance! \ud83c\udf89",
        "location": "127\n              \n            \n      \n  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n            \n      \n        \n                4 Comments"
      }
    ],
    "similar_profiles": [
      {
        "link": "https://www.linkedin.com/in/yeandrew?trk=public_profile_samename-profile",
        "name": "Andrew Ye",
        "summary": "Sensor Dev @ SpaceX",
        "location": "Hawthorne, CA"
      },
      {
        "link": "https://www.linkedin.com/in/andrew-z-ye?trk=public_profile_samename-profile",
        "name": "Andrew Ye",
        "summary": "",
        "location": "Ann Arbor, MI"
      },
      {
        "link": "https://www.linkedin.com/in/andrewye16?trk=public_profile_samename-profile",
        "name": "Andrew Ye",
        "summary": "",
        "location": "Greater Boston"
      },
      {
        "link": "https://www.linkedin.com/in/andrew-ye-6223b0168?trk=public_profile_samename-profile",
        "name": "Andrew Ye",
        "summary": "",
        "location": "San Francisco Bay Area"
      }
    ],
    "recommendations": [],
    "publications": [],
    "courses": [],
    "languages": [],
    "organizations": [],
    "projects": [],
    "awards": [],
    "score": []
  }
]