[
  {
    "fullName": "Harshil Avlani",
    "linkedin_internal_id": "1372463963",
    "first_name": "Harshil",
    "last_name": "Avlani",
    "public_identifier": "harshil-avlani-b8b775323",
    "background_cover_image_url": "https://static.licdn.com/aero-v1/sc/h/5q92mjc5c51bjlwaj3rs9aa82",
    "profile_photo": "https://static.licdn.com/aero-v1/sc/h/9c8pery4andzj6ohjkjp54ma2",
    "headline": "CS + Physics @ MIT",
    "location": "218 followers\n          \n          \n              217 connections",
    "about": "",
    "experience": [
      {
        "position": "Research Intern with the Quanta Group",
        "company_url": "https://www.linkedin.com/company/research-laboratory-of-electronics-at-mit?trk=public_profile_experience-item_profile-section-card_subtitle-click",
        "company_image": "https://media.licdn.com/dms/image/v2/D4E0BAQEcoeLgEEK4ng/company-logo_100_100/company-logo_100_100/0/1719293675264?e=2147483647&v=beta&t=tr1VjvB08wz5LZ7_kM9WaPpzsVDpKb9rV0ESfeI6ybQ",
        "company_name": "Research Laboratory of Electronics at MIT",
        "location": null,
        "summary": "",
        "starts_at": "Oct 2024",
        "ends_at": "Present",
        "duration": "6 months"
      },
      {
        "position": "Research Intern at the Quantum Mechanical Engineering Lab",
        "company_url": "https://www.linkedin.com/school/arizona-state-university/?trk=public_profile_experience-item_profile-section-card_subtitle-click",
        "company_image": "https://media.licdn.com/dms/image/v2/C560BAQHDGjY1IZJuog/company-logo_100_100/company-logo_100_100/0/1631309406468?e=2147483647&v=beta&t=xqmIquQcVwaLLhUPNVHno3nJ2AtyKRyOOpo5SBo39ao",
        "company_name": "Arizona State University",
        "location": null,
        "summary": "",
        "starts_at": "May 2023",
        "ends_at": "Aug 2024",
        "duration": "1 year 4 months"
      },
      {
        "position": "Research Intern with the Hauser Research Group",
        "company_url": "https://www.linkedin.com/school/university-of-alabama/?trk=public_profile_experience-item_profile-section-card_subtitle-click",
        "company_image": "https://media.licdn.com/dms/image/v2/C4D0BAQFxedRB7q9Ceg/company-logo_100_100/company-logo_100_100/0/1630537506680/university_of_alabama_logo?e=2147483647&v=beta&t=sUl7qWXwbBiOPywYGgknFHpmqh72y2xU_ST1yn0f1zw",
        "company_name": "The University of Alabama",
        "location": null,
        "summary": "",
        "starts_at": "Sep 2022",
        "ends_at": "May 2023",
        "duration": "9 months"
      },
      {
        "position": "Research Intern at the SEFCOM Lab",
        "company_url": "https://www.linkedin.com/school/arizona-state-university/?trk=public_profile_experience-item_profile-section-card_subtitle-click",
        "company_image": "https://media.licdn.com/dms/image/v2/C560BAQHDGjY1IZJuog/company-logo_100_100/company-logo_100_100/0/1631309406468?e=2147483647&v=beta&t=xqmIquQcVwaLLhUPNVHno3nJ2AtyKRyOOpo5SBo39ao",
        "company_name": "Arizona State University",
        "location": null,
        "summary": "",
        "starts_at": "May 2022",
        "ends_at": "Aug 2022",
        "duration": "4 months"
      },
      {
        "position": "Quantum Software Student",
        "company_url": "https://www.linkedin.com/company/mit-beaver-works-summer-institute?trk=public_profile_experience-item_profile-section-card_subtitle-click",
        "company_image": "https://media.licdn.com/dms/image/v2/C560BAQECCPZpgUpArA/company-logo_100_100/company-logo_100_100/0/1677965073863?e=2147483647&v=beta&t=sNUlempCGXIPyuxzAxtj5TTtFlmP_gQPY7-1-7vAVrY",
        "company_name": "MIT Beaver Works Summer Institute",
        "location": null,
        "summary": "",
        "starts_at": "May 2022",
        "ends_at": "Aug 2022",
        "duration": "4 months"
      }
    ],
    "education": [
      {
        "college_url": "https://www.linkedin.com/school/mit/?trk=public_profile_school_profile-section-card_image-click",
        "college_name": "Massachusetts Institute of Technology",
        "college_image": "https://media.licdn.com/dms/image/v2/D560BAQH-UXRfIDIKug/company-logo_100_100/company-logo_100_100/0/1689799729035/mit_logo?e=2147483647&v=beta&t=2BcyEkKb9m86JDvxtNLfDVfyept76unhOFNf5Wt_Vp4",
        "college_degree": "Bachelor's degree",
        "college_degree_field": null,
        "college_duration": " - ",
        "college_activity": ""
      },
      {
        "college_url": "https://www.linkedin.com/school/basis-chandler/?trk=public_profile_school_profile-section-card_image-click",
        "college_name": "BASIS Chandler",
        "college_image": "https://media.licdn.com/dms/image/v2/D560BAQE65ja-fHNVxA/company-logo_100_100/company-logo_100_100/0/1697772444150/basis_chandler_logo?e=2147483647&v=beta&t=5zOhg8gCHfchnrYR6hu-0pCmjPnkQ_UQafhAOjqwvtA",
        "college_degree": "High School",
        "college_degree_field": null,
        "college_duration": " - ",
        "college_activity": ""
      }
    ],
    "articles": [],
    "description": {
      "description1": "Research Laboratory of Electronics at MIT",
      "description1_link": "https://www.linkedin.com/company/research-laboratory-of-electronics-at-mit?trk=public_profile_topcard-current-company",
      "description2": "Massachusetts Institute of Technology",
      "description2_link": "https://www.linkedin.com/school/mit/?trk=public_profile_topcard-school",
      "description3": ""
    },
    "activities": [],
    "volunteering": [],
    "certification": [],
    "people_also_viewed": [
      {
        "link": "https://www.linkedin.com/company/pytorch?trk=public_profile_relatedPosts_face-pile-cta",
        "name": "",
        "summary": "PyTorch\n        \n              \n          Great to see the newly announced Bamba-9B, an inference-efficient Hybrid Mamba2 model \ud83d\udc0d trained by IBM, Princeton, CMU, and UIUC on\u00a0completely open data used PyTorch FSDP to train these novel architecture models and they are integrating inference with vLLM, which recently joined the PyTorch Ecosystem.",
        "location": "167"
      },
      {
        "link": "https://www.linkedin.com/in/david-hollinger1?trk=public_profile_relatedPosts_face-pile-cta",
        "name": "",
        "summary": "David Hollinger\n        \n              \n          I\u2019m thrilled to share that my \ud835\udde7\ud835\udddb\ud835\udddc\ud835\udde5\ud835\uddd7 first-author paper, \"A Hierarchical-Based Learning Approach for Multi-Action Intent Recognition\" was recently accepted for publication! \u270d \ud83c\udf89 \n\nPersonally, this paper was my favorite among a collection of studies in my dissertation, \"The Role of Artificial Intelligence for Human Intent Prediction Across Dynamic Actions Using Wearable Sensors.\"\n\n\ud83c\udf0d \ud835\udddb\ud835\uddf2\ud835\uddff\ud835\uddf2\u2019\ud835\ude00 \ud835\ude01\ud835\uddf5\ud835\uddf2 \ud835\uddef\ud835\uddf6\ud835\uddf4 \ud835\uddfd\ud835\uddf6\ud835\uddf0\ud835\ude01\ud835\ude02\ud835\uddff\ud835\uddf2: Predicting human motion based on the user's intent at the joint level has potential applications for wearable robotics, rehabilitation devices, and biomechanics research.\n\n\ud835\uddd5\ud835\uddee\ud835\uddf0\ud835\uddf8\ud835\uddf4\ud835\uddff\ud835\uddfc\ud835\ude02\ud835\uddfb\ud835\uddf1:\n\ud83d\udc49 Since the human motor system operates from general to specific, a hierarchical-based learning approach could result in a more effective control scheme.\n\ud83d\udc49 The findings of this novel approach could contribute to the field\u2019s understanding of how to optimize AI-based methods that mimic the human motor system to potentially integrate with exoskeletons.\n\n\ud835\udde0\ud835\uddf2\ud835\ude01\ud835\uddf5\ud835\uddfc\ud835\uddf1\ud835\ude00:\n\ud83d\udc49 We developed a novel hierarchical-based learning method that combines action classification (e.g., walking, running, kneeling) with joint-level predictions.\u00a0\n\ud83d\udc49 Explored action-generic vs. action-specific models for predicting joint angles at the ankle, knee, and hip.\n\ud83d\udc49 We trained deep learning and machine learning models on data collected from participants wearing inertial sensors.\n\n\ud835\udde5\ud835\uddf2\ud835\ude00\ud835\ude02\ud835\uddf9\ud835\ude01\ud835\ude00:\n\ud83d\udc49 Found that action-generic models trained on large, diverse datasets outperform hierarchical-based methods for multi-action scenarios.\n\n\ud835\uddde\ud835\uddf2\ud835\ude06 \ud835\udde7\ud835\uddee\ud835\uddf8\ud835\uddf2\ud835\uddee\ud835\ude04\ud835\uddee\ud835\ude06\ud835\ude00:\n\ud83d\udc49 Demonstrated the potential for IMU-driven, task-agnostic models to improve exoskeleton control and movement prediction accuracy.\n\ud83d\udc49 Enhancing human intent prediction across a wide range of tasks is essential for more robust and effective control of exoskeleton technology.\n\n\ud835\uddea\ud835\uddf5\ud835\uddee\ud835\ude01\u2019\ud835\ude00 \ud835\udde1\ud835\uddf2\ud835\ude05\ud835\ude01?\n\ud83d\udc49 We\u2019re calling for more diverse datasets incorporating cyclic and non-cyclic activities to make these systems even more robust and applicable.\u00a0\n\ud83e\uddbf \ud83d\udca1\u00a0The applications from this study range from improving the control of wearable robotics based on user intent to other biomechanics-related topics (e.g., sports performance and rehabilitation interventions).\n\n\ud83d\udc4f Huge s/o to co-authors: Michael Zabala Howard Chen Mark Schall Ryan Pollard\n\nLink to the full article in the comments.",
        "location": "44\n              \n            \n      \n  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n            \n      \n        \n                4 Comments"
      },
      {
        "link": "https://in.linkedin.com/in/raj-abhijit-dandekar-67a33118a?trk=public_profile_relatedPosts_face-pile-cta",
        "name": "",
        "summary": "Raj Abhijit Dandekar\n        \n              \n          What society values may not be the best thing for you.\n\nWhen I applied for grad school, I got admits from MIT, Stanford, Purdue, CMU and UIUC.\n\nI knew I wanted to do a PhD.\u00a0I chose MIT immediately, because it was ranked number 1. \n\nI never thought whether it was a good decision or not. \n\nI just assumed that it\u2019s a good decision because it\u2019s rated higher than the other universities.\n\nWhen I joined MIT, all that rank 1 noise disappeared.\n\nAll I was surrounded by was my lab, my lab group members and my advisor. \n\nI had never carefully considered whether this research group was a good fit for me. I just joined the first MIT research group which came my way.\n\nThis led to a miserable first 2 years of PhD for me. \n\nThe group was not a good fit and the research topic was also not a good fit.\n\nThese lost 2 years were a result of choosing what society values more (university ranking) rather than what is a better thing for me.\n\nWhen I look back, I should have done the following:\n\n(1) I should have made a list of all research groups I was interested in, from all universities I was selected to.\n\n(2) I should have spoken with the lab advisor from all these research groups and understood their vision.\n\n(3) I should have learnt more about the group culture by talking to past members of the group. Graduating members are usually very honest. They would tell you if the culture is toxic, if the advisor is micromanaging etc.\n\n(4) I should have looked at the group website to look at the publication rate, what do the alumni end up doing etc? If the average graduation time is 8 years, it\u2019s a red flag.\n\nAfter doing the above 4 things, I should have selected the best research group for me.\n\nI should have selected the research group whose culture aligns well with my personality.\n\nSociety values ranking. \n\nHowever, when you enter the university for a PhD, the ranking does not matter. Your research group matters. What you do every day after waking up matters.\n\nAnd if you blindly select universities based on the ranking, the research group won\u2019t be a good fit and it would lead to a terrible PhD experience.\n\nIt turns out that society misguides people in many other professions including:\n\n- Choosing to prepare for IIT-JEE just because society prefers that you are an IITian\n- Choosing a job just because society prefers higher salary\n- Choosing to not do a startup because the society (your parents) don\u2019t approve\n\nAlways question yourself before blindly making decisions based on what the society values. It might not be the best thing for you.\n\nGoing against traditional societal values is hard in the short term, but it pays off in the long run.\n\nP.S: In the photo, you can see me during my first day at MIT!",
        "location": "308\n              \n            \n      \n  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n            \n      \n        \n                6 Comments"
      },
      {
        "link": "https://www.linkedin.com/in/varungoyal23?trk=public_profile_relatedPosts_face-pile-cta",
        "name": "",
        "summary": "Varun Goyal\n        \n              \n          \ud83c\udf1f \ud835\udc03\ud835\udc2b\ud835\udc1e\ud835\udc1a\ud835\udc26\ud835\udc22\ud835\udc27\ud835\udc20 \ud835\udc01\ud835\udc22\ud835\udc20, \ud835\udc01\ud835\udc2e\ud835\udc22\ud835\udc25\ud835\udc1d\ud835\udc22\ud835\udc27\ud835\udc20 \ud835\udc01\ud835\udc22\ud835\udc20\ud835\udc20\ud835\udc1e\ud835\udc2b \ud83c\udf1f\n\nLast May, I embarked on an incredible journey with WisdomAI right after graduating from UIUC, and it has been nothing short of a dream run! Starting my career with a passionate, dynamic team like this one has been an amazing experience. \ud83d\ude80\n\nHere\u2019s what I\u2019ve absolutely loved about my time at WisdomAI so far:\n\n1\ufe0f\u20e3 Ownership Sparks Passion\nWhen you\u2019re empowered with the right motivation and a sense of ownership, the task transforms into a pursuit. I\u2019ve cherished the freedom to take charge of my projects, driven by curiosity for achieving results rather than just deadlines.\n\n2\ufe0f\u20e3 Culture of Growth & Impact\nI\u2019m deeply grateful to the founders and my team for cultivating an environment of insane growth while delivering great value to our customers every single day. Huge thanks to the founders - Soham, Sharvanath, Kapil, and Guilherme for fostering this environment.\n\n3\ufe0f\u20e3 The Power of Team Energy\nThe motivation and drive of the people around you can make all the difference. Being surrounded by such an energetic, supportive team has truly set the trajectory for my career. \n\nAs we step into this new year, we\u2019re doubling down with more energy, sharper focus, and even bigger goals for our startup. Here\u2019s to a year of innovation, impact, and scaling new heights together! \ud83d\udca1\ud83c\udf0d\n\n\n\n#StartupJourney #GrowthMindset #WisdomAI #Teamwork #Innovation #NewYearGoals #CareerJourney",
        "location": "136\n              \n            \n      \n  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n            \n      \n        \n                7 Comments"
      },
      {
        "link": "https://bd.linkedin.com/in/ershad-khandker-0b696a54?trk=public_profile_relatedPosts_face-pile-cta",
        "name": "",
        "summary": "Ershad Khandker\n        \n              \n          \" Flatiron Institute senior research scientist Shiwei Zhang and his team have utilized the Hubbard model to computationally re-create key features of the superconductivity in materials called cuprates that have puzzled scientists for decades.\n\nSuperfast hovering trains, long-distance power transmission without energy loss, and quicker MRI scanners \u2014 all these incredible technological innovations could be within reach if we could develop a material that conducts electricity without any resistance, or \u201csuperconducts,\u201d at approximately room temperature.\n\nIn a paper recently published in the journal Science, researchers report a breakthrough in our understanding of the origins of superconductivity at relatively high (though still frigid) temperatures. The findings concern a class of superconductors that has puzzled scientists since 1986, called \u2018cuprates.\u2019\n\nThere was tremendous excitement when cuprate superconductors were discovered [in 1986], but no understanding of why they remain superconductive at such high temperatures,\u201d says Shiwei Zhang, a senior research scientist at the Flatiron Institute\u2019s Center for Computational Quantum Physics (CCQ). \u201cI think it\u2019s surprising to everybody that almost 40 years later, we still don\u2019t quite understand why they do what they do.\n\n\u2757\ufe0fIn the new paper, Zhang and his colleagues successfully re-created features of cuprate superconductivity with a simple model called the two-dimensional Hubbard model, which treats the materials as if they were electrons moving around a quantum chessboard. The breakthrough comes only a few years after the same researchers demonstrated that the simplest version of this model couldn\u2019t perform such a feat. Such straightforward models can spark a deeper understanding of physics, says study co-author Ulrich Schollw\u00f6ck, a professor at the University of Munich. \u2757\ufe0f\ud83d\udc48\n\nThe idea in physics is to keep the model as simple as possible because it\u2019s difficult enough on its own,\u201d Schollw\u00f6ck says. \u201cSo in the beginning we studied the simplest version imaginable.\u201d\n\nEnhancements to the Hubbard Model\nIn the new study, the researchers added to the 2D Hubbard model the ability for electrons to make diagonal hops, like bishops in chess. With this tweak and thousands of weeks-long simulations on supercomputers, the researchers\u2019 model captured the superconductivity and several other key features of cuprates previously found in experiments. By showing that the humble Hubbard model can describe cuprate superconductivity, the authors prove its worth as a platform for understanding why and how superconductivity emerges.\"\n\nAfter over 30 years of intense effort by the community without many reliable answers, it\u2019s often been argued that solving the Hubbard model would have to wait for a quantum computer,\u201d Zhang says. \u201cThis effort will not only advance research in high-temperature superconductivity, but hopefully also spur more research using \u2018classical\u2019 computation to explore the wonders of the quantum world.\u201d",
        "location": ""
      },
      {
        "link": "https://www.linkedin.com/in/jae-won-chung-cs?trk=public_profile_relatedPosts_face-pile-cta",
        "name": "",
        "summary": "Jae-Won Chung\n        \n              \n          Perseus was accepted to appear at SOSP'24!\n\nPerseus is an energy optimization system that identifies and reduces \"energy bloat\" form large model training. A quick blog post: https://lnkd.in/gjKMQ2wR\n\nPerseus tackles a very real problem -- power delivery being one of the largest bottlenecks for AI datacenters. What I've cited in the blog post is CEO Mark Zuckerberg's interview, but the AI power problem has been hitting the headlines every day.\n\nIn this context, what Perseus hopes to achieve is to reduce the total energy consumption of a training job without slowing it down at all, thus reducing average power draw as well. This being feasible means that some portion of energy consumed by training wasn't necessarily contributing to end-to-end throughput. We called this wastage energy bloat.\n\nThough early-stage, Perseus is already open-source as part of Zeus. We're always eager to chat with our users, so please don't hesitate to reach out to us. https://lnkd.in/gHSNry7h\n\nFinally, a shoutout to the awesome Perseus team Yile Gu, Insu Jang, Luoxi Meng, Nikhil Bansal, and Mosharaf Chowdhury. I'm such a lucky man to have worked with everyone!\n\nComputer Science and Engineering at the University of Michigan\n\n#genai #energy",
        "location": "112\n              \n            \n      \n  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n            \n      \n        \n                7 Comments"
      },
      {
        "link": "https://www.linkedin.com/in/prakhar-sinha-57a412201?trk=public_profile_relatedPosts_face-pile-cta",
        "name": "",
        "summary": "Prakhar Sinha\n        \n              \n          A few short days ago, I wrapped up my research position at UC Davis Health with Professor Farzad Fereidouni. My role at the lab entailed a specialization in machine learning and computer vision and I'm excited to share what I was able to accomplish with everyone. \n\nI worked on two projects during my time at the lab. The first one was something I called \"Kernel Generation for Image Similarity\" (https://lnkd.in/ghsY73ts). It was to process an image such that it would look like it was H&E stained. I learned a lot about the basics of histology and digital histology through this process. The most novel part of this approach was using Wiener deconvolution to generate a kernel that would be used to enhance image similarity (typically using SSIM, MSE or a combination of both). \n\nA big part of this process was optimization. I learned how to use Python libraries such as Cupy and other tools to GPU accelerate a lot of these image-processing optimization problems.\n\nMy second project and my most meaningful contribution was called \"FastSAM-needle-biopsy\" (https://lnkd.in/gXXydq-X). The objective of this project was to use the FastSAM image segmentation network to accurately generate image segmentation masks of live tissue such that a microscope would only scan the relevant parts of an image. Here is step by step walkthrough of the image processing pipeline:\n\n1) VB.NET (Darius) application calls a DLL (compiled from csharp.NET)\n2) DLL calls FastSAM image segmentation code using Python.NET\n3) FastSAM segments image and returns image segmentation bitmask and as well as the fastest path to visit every bit (Traveling Salesman Problem)\n4) Python returns values are returned to DLL using JSON as a reliable data transfer solution\u00a0\n5) DLL returns an object that can be parsed by VB.NET\n\nFastSAM is a faster version of Meta Research's Segment Anything Model and I used it to greatly speed up development time on this project. It was a big challenge to integrate such cutting-edge, machine-learning driven, image processing pipelines into a legacy codebase that was written in Visual Basic .NET but thanks to tools such as DLLs, JSON, and C#, I was able to figure it out!\n\nI am very grateful for the time I spent in the lab. I feel like I developed some great programming skills, especially in computer vision, that will prove useful for the rest of my career. I'd like to give special thanks to Professor Fereidouni, Ruby Mascareno, Willy Ju, Dena Sayrafi, Ruben Gnanaruban, Inyola, Antara Mallick, and Jayla. \n\nThe link is here if you'd like to see my lab report going over everything I did in more technical detail and with a few pictures!\n\nhttps://lnkd.in/gRpZVmjG\n\n#computervision #machinelearning #AI #histology",
        "location": "67\n              \n            \n      \n  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n            \n      \n        \n                10 Comments"
      },
      {
        "link": "https://www.linkedin.com/in/aavu?trk=public_profile_relatedPosts_face-pile-cta",
        "name": "",
        "summary": "Raghavasimhan Sankaranarayanan, Ph.D.\n        \n              \n          It\u2019s been an honor working with Gil Weinberg! Thanks so much!\n\nThis demo is from one of the chapters in my thesis on #AI driven raga agnostic automatic accompaniment for alapana (non-rhythmic improvisations) in South Indian Classical Music. Since the algorithm is raga agnostic, the system can accompany for any raga performed!\n\nMore demos on a violin playing #robot coming soon!\n\n#MusicTechnology #MachineLearning #HumanRobotInteraction #HumanComputerInteraction\n#AutomaticAccompaniment",
        "location": "217\n              \n            \n      \n  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n            \n      \n        \n                32 Comments"
      },
      {
        "link": "https://www.linkedin.com/in/waynerad?trk=public_profile_relatedPosts_face-pile-cta",
        "name": "",
        "summary": "Wayne Radinsky\n        \n              \n          \"Are large language models superhuman chemists?\"\n\nSo what these researchers did was make a test -- a benchmark. They made a test of 7,059 chemistry questions, spanning the gamut of chemistry: computational chemistry, physical chemistry, materials science, macromolecular chemistry, electrochemistry, organic chemistry, general chemistry, analytical chemistry, chemical safety, and toxicology.\n\nThey recruited 41 chemistry experts to carefully validate their test.\n\nThey devised the test such that it could be evaluated in a completely automated manner. This meant relying on multiple-choice questions rather than open-ended questions more than they wanted to. The test has 6,202 multiple-choice questions and 857 open-ended questions (88% multiple-choice). The open-ended questions had to have parsers written to find numerical answers in the output in order to test them in an automated manner.\n\nIn addition, they ask the models to say how confident they are in their answers.\n\nBefore I tell you the ranking, the researchers write:\n\n\"On the one hand, our findings underline the impressive capabilities of LLMs in the chemical sciences: Leading models outperform domain experts in specific chemistry questions on many topics. On the other hand, there are still striking limitations. For very relevant topics the answers models provide are wrong. On top of that, many models are not able to reliably estimate their own limitations. Yet, the success of the models in our evaluations perhaps also reveals more about the limitations of the exams we use to evaluate models -- and chemistry -- than about the models themselves. For instance, while models perform well on many textbook questions, they struggle with questions that require some more reasoning. Given that the models outperformed the average human in our study, we need to rethink how we teach and examine chemistry. Critical reasoning is increasingly essential, and rote solving of problems or memorization of facts is a domain in which LLMs will continue to outperform humans.\"\n\n\"Our findings also highlight the nuanced trade-off between breadth and depth of evaluation frameworks. The analysis of model performance on different topics shows that models' performance varies widely across the subfields they are tested on. However, even within a topic, the performance of models can vary widely depending on the type of question and the reasoning required to answer it.\"\n\nAnd with that, I'll tell you the rankings. You can log in to their website at ChemBench.org and see the leaderboard any time for the latest rankings. At this moment I am seeing:\n\ngpt-4: 0.48\nclaude2: 0.29\nGPT-3.5-Turbo: 0.26\ngemini-pro: 0.25\nmistral_8x7b: 0.24\ntext-davinci-003: 0.18\nPerplexity 7B Chat: 0.18\ngalactica_120b: 0.15\nPerplexity 7B online: 0.1\nfb-llama-70b-chat: 0.05",
        "location": "3"
      },
      {
        "link": "https://www.linkedin.com/in/nathaniel-borusowski?trk=public_profile_relatedPosts_face-pile-cta",
        "name": "",
        "summary": "Nathaniel Borusowski\n        \n              \n          One of the best resume templates I have found and that I personally use, for those struggling to find the perfect template. \n\nJake's Resume is used by many, because it is so simple and easy to read, and great for filling in lots of information. In addition, it is LaTex compatible!! \n\nFind the link here https://lnkd.in/e-5dpy66",
        "location": "3"
      },
      {
        "link": "https://www.linkedin.com/in/aqib-syed-71710a79?trk=public_profile_relatedPosts_face-pile-cta",
        "name": "",
        "summary": "Aqib Syed\n        \n              \n          I'm excited to share the first version of my EE 263 Course Notes. I\u2019ve been working on these notes over the past few months, starting back when I TA'd EE 263 - Linear Dynamical Systems this past Summer. The course is offered by the Electrical Engineering Department at Stanford. It\u2019s also cross-listed with the Institute for Computational and Mathematical Engineering (ICME).\nThe course is mainly intended for first-year Ph.D. students in engineering fields (like Electrical Engineering, Aero/Astro, etc.), and it\u2019s a recommended prerequisite for the Convex Optimization course, EE 364a. Having taken EE 263 before EE 364a, I can say firsthand how crucial it is in helping you understand the material for the latter course.\nEE 263 focuses on applied linear algebra and dynamical systems, covering core concepts like range, null space, matrix exponentials, as well as very relevant applications, like least-squares estimates.\nWhile assisting in teaching the course, I often heard from students that the lecture slides alone weren\u2019t always enough for them to fully grasp the material.\nTo help with this, I started writing more detailed notes that expand on the course content. These notes are helpful as a companion to the lectures but aren't completely self-contained\u2014especially in the sections on linear dynamical systems. I plan to continue adding more content and examples over the coming months.\nOne part of these notes I\u2019m particularly proud of is the plots and visualizations/figures I made to explain key concepts, which were created using some convex combination of LaTeX, Julia and Python.\nHere is the link to the notes:\nhttps://lnkd.in/ggBNKQ8E",
        "location": "151\n              \n            \n      \n  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n            \n      \n        \n                7 Comments"
      },
      {
        "link": "https://www.linkedin.com/in/kyrian-adimora-2b111a205?trk=public_profile_relatedPosts_face-pile-cta",
        "name": "",
        "summary": "Kyrian Adimora\n        \n              \n          As a Computer Science Ph.D. candidate researching at the intersection of HPC and AI, I'm witnessing an unprecedented technological symbiosis. Modern AI models have grown to phenomenal scales - with some reaching trillions of parameters - demanding computational resources that would have seemed unimaginable just years ago.\nHigh-Performance Computing (HPC) is the backbone enabling these breakthroughs. Through advanced parallel processing, distributed training architectures, and optimized hardware accelerators, HPC infrastructure is making it possible to:\nTrain massive language models across thousands of GPUs\nProcess petabytes of training data efficiently\nEnable breakthrough capabilities in scientific computing and AI research\nWhile we've made remarkable progress in optimizing inference for edge devices, the fundamental training of these models still requires substantial computational power. This creates fascinating research challenges in distributed systems, model parallelism, and hardware-software co-design.\nFor those interested in this field, understanding the synergy between HPC and AI is crucial. What aspects of large-scale AI computing interest you most? Let's discuss the future of computational infrastructure that's driving AI innovation.",
        "location": "24"
      },
      {
        "link": "https://in.linkedin.com/in/aryanng?trk=public_profile_relatedPosts_face-pile-cta",
        "name": "",
        "summary": "Aryan Gupta\n        \n              \n          It\u2019s been a while since I last posted, so I thought I\u2019d share a few things I\u2019ve been working/worked on over the past 6-7 months:\n\n1)Building a Custom Compiler \nAfter getting really interested in Compiler Design last semester, I took it upon myself to learn how to implement a custom compiler. Spent my summer vacation building different stages of compilation. Honestly, it was challenging but super rewarding.(will be posting about in depth)\n\n2) Exploring Vision Transformers\nAs part of an academic project on diabetic retinopathy. I dived deep into these models and learned a lot about computer vision. \n\n3)Web Scrapers for Placement Forums\nBuilt a few web scrapers for scraping placement-related forums. Unfortunately, I lost the code because I forgot to push it to GitHub before formatting my laptop (tough lesson learned here).\n\n4)YouTube Watch Party App\nI\u2019ve been working on a YouTube Watch Party app to learn WebSockets and WebRTC. It\u2019s nearly finished\u2014just needs a few final touches and some code cleanup before I host it. This project has been a great way to test out some ideas.\n\n5)DSA Practice\nSolved 400+ problems(Leetcode,GFG,Codeforces)\u2014not something to brag about, given the market conditions, but it\u2019s part of staying sharp in DSA.\n\n6)Static Site Generator in Python\nCurrently working on a Static Site Generator in Python as part of Boot.dev\u2019s course. It\u2019s been fun to build, and I\u2019m learning more about how static sites work under the hood.\n\nA couple of things I couldn't finish (but plan to get back to):\n\n1)Redis Clone (C++ - Codecrafters)\nGot through 22/40 tasks but hit a nasty bug that I couldn\u2019t figure out(skills issues!!). Will take it up again when I have more time (or when I level up my debugging skills!).\n\n2)Next.js Application Tracker\nStarted building an app to track all my applications in one place. Definitely want to pick this back up when I have a bit more bandwidth.\n\nRepositories for all the above projects:\nCompiler : https://lnkd.in/gu-ZX6YF\nYoutubeWatchParty : https://lnkd.in/gbQhsafD (Don\u2019t mind the unstructured code\u2014I was testing out ideas!)\nNext.js Application Tracker : https://lnkd.in/gemYMGnu\nRedis-clone : \u00a0https://lnkd.in/gUkXq6tx)\nStatic Site Generator Repo : \u00a0https://lnkd.in/g8Np4Ada\nSwinTransformers : https://lnkd.in/gAHptM2e\nLeetcode Profile : https://lnkd.in/gwer2GNH",
        "location": "52\n              \n            \n      \n  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n            \n      \n        \n                2 Comments"
      },
      {
        "link": "https://www.linkedin.com/in/indranil-gupta-04784a38?trk=public_profile_relatedPosts_face-pile-cta",
        "name": "",
        "summary": "Indranil Gupta\n        \n              \n          Do \"musical lectures\" work? An experiment in my class...\nMy Fall24 class midterm exam had 5 questions, each worth 20 pts. \nFor 4 of the 5 questions, the median score < 20.\nExcept 1 question, whose class-wide median was 20 (i.e., > 50% students got a perfect score!)\nThat q was on Lamport+vector timestamps...the only topic in the class with a \"song\" lecture.",
        "location": "8\n              \n            \n      \n  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n            \n      \n        \n                1 Comment"
      },
      {
        "link": "https://www.linkedin.com/in/daveanderson130?trk=public_profile_relatedPosts_face-pile-cta",
        "name": "",
        "summary": "Dave Anderson\n        \n              \n          I use (and like) Edge Impulse as a web-based GUI for teaching applied neural networks and tinyML in my graduate ML class here at UMD, but I wasn't able to find a hardware kit for using line level audio and piezoelectric transducers as sensors quickly and easily (as in, something that you can get a whole class of students up and running with in one semester).\n\nI worked with two grad students (Rob Neiburg and Lukas Aanonsen) to design and build a hardware kit based around the Raspberry Pi pico for exactly this purpose. This board allows the user to run real-time, low-power classification tasks on data from line-level audio (e.g. guitar!) or piezo sensors (vibration signal detection) with no tweaking to default EI firmware. It's got a selector switch for either piezo or audio inputs, and three LED outputs to indicate which of three classes the signal fits into - with the option to break out into many more outputs/classes.\n\nI should be posting more details soon at my website, and would be happy to share designs for anyone also interested in using this as a teaching tool.\n\n#edgeimpulse #deeplearning #tinyML",
        "location": "25\n              \n            \n      \n  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n            \n      \n        \n                1 Comment"
      },
      {
        "link": "https://www.linkedin.com/in/saiyurisuresh?trk=public_profile_relatedPosts_face-pile-cta",
        "name": "",
        "summary": "Saiyuri Suresh\n        \n              \n          This is so awesome! Theodore Zhao and Yu Gu at Microsoft along with brilliant co-authors at Providence, the University of Washington and Microsoft have introduced BiomedParse, an AI medical image analysis model.\u00a0It integrates segmentation, detection, and recognition tasks across nine imaging modalities, such as CT scans, MRIs, X-rays, and pathology images. This allows medical professionals to analyze systemic diseases holistically rather than relying on single-modality tools\u200b. \n\nWhat is especially interesting to me is the use of text-driven analysis. BiomedParse allows medical professionals to conduct image analysis using simple natural language prompts. This significantly streamlines the process and makes image analysis more efficient. \n\nIt\u2019s incredible to witness how cutting-edge AI and proteomics are shaping the future of healthcare! Looking forward to its broader adoption and impact on personalised medicine. Congrats to the entire team on this achievement. \n\n\ud83d\udd17 Read more about their findings here: https://lnkd.in/gqpJ8TUS\n\n\ud83d\udd17 Q&A with Prof. Sheng Wang at UW\nhttps://lnkd.in/g8mXbdCs",
        "location": "20"
      },
      {
        "link": "https://www.linkedin.com/company/biosimmlab?trk=public_profile_relatedPosts_face-pile-cta",
        "name": "",
        "summary": "Biomedical Flows Simulation & Multiscale Modeling Lab\n        \n              \n          \ud83d\ude80 New paper alert! \ud83d\ude80 \n\nOur latest research paper, \"Taylor series error correction network for super-resolution of discretized partial differential equation solutions,\" by PhD student Wenzhuo Xu, is live in the Journal of Computational Physics. \n\nIn this work, in collaboration with Chris McComb, we developed a novel machine learning model to correct discretization errors in numerical solutions of PDEs.\n\n\u25b6 The graph neural network can reconstruct high-resolution physical dynamics from          low-resolution data.\n\n\u25b6 We demonstrate generalization capabilities for super-resolution across several PDE solutions.\n\n\u25b6 Compared with neural operators, the computational cost is reduced by 47%.\n\nCheck out the full paper here: https://lnkd.in/dR4xruUC\n\n#MachineLearning #EgineeringSimulations",
        "location": "12"
      },
      {
        "link": "https://www.linkedin.com/in/pooria-namyar?trk=public_profile_relatedPosts_face-pile-cta",
        "name": "",
        "summary": "Pooria Namyar\n        \n              \n          Check out the new article about our NSDI'24 paper, \"Solving Max-Min Fair Resource Allocations Quickly on Large Graphs\"! \n\nFair and efficient resource allocation is crucial in today's (multi-tenant) cloud environments. In practice, the most common definition of fairness is max-min fairness, but achieving max-min fairness at scale has become a practical bottleneck in many domains, such as Traffic Engineering and Cluster Scheduling.\n\nTo address this, we have developed scalable algorithms that (1) Pareto-dominate existing techniques in fairness, efficiency, and speed and (2) provide operators greater flexibility in controlling the trade-offs between these factors. Our methods are general and applicable to any graph-based resource allocation problem, including Traffic Engineering and Cluster Scheduling. We have successfully deployed our solution in Microsoft Azure's WAN traffic engineering pipeline, providing a 3\u00d7 average speedup (up to 5.4\u00d7) without any impact on fairness and efficiency compared to Azure's previous allocator.\n\nA big shoutout to my co-authors Behnaz Arzani, Srikanth Kandula, Santiago Segarra, Daniel Crankshaw, Umesh Krishnaswamy, Ramesh Govindan, and Himanshu Raj!\n\nPaper: https://lnkd.in/gKNn6KAr\nCode: https://lnkd.in/gpFtasfq",
        "location": "49\n              \n            \n      \n  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n            \n      \n        \n                3 Comments"
      },
      {
        "link": "https://in.linkedin.com/in/vidhi-shukla-377268245?trk=public_profile_relatedPosts_face-pile-cta",
        "name": "",
        "summary": "Vidhi Shukla\n        \n              \n          \ud83c\udf1f Thrilled to Announce Our Latest Research! \ud83c\udf1f\n\nI am excited to share our recently published paper, \"Advancing Prenatal Diagnostics: A Novel Approach Using Machine Learning to Assess Fetal Well-being,\" in the February 2024 issue of TIJER. This groundbreaking research introduces a robust ML-driven framework for the early detection and prediction of fetal health issues, utilizing cardiotocographic data.\n\nIn this study, I took a leading role in developing the methodology and analyzing the data, employing sophisticated machine learning algorithms such as SVM, Random Forest, KNN, LVQ, and advanced ensemble models including XGBoost, AdaBoost, and LightGBM. These tools have significantly surpassed traditional monitoring techniques in predicting fetal health, offering deeper insights and potential for early intervention.\n\nI am deeply grateful for the guidance and mentorship of Dr. Santosh Kumar Singh  and Rimsy Dua, whose profound insights and support have been instrumental in shaping this research. This achievement also wouldn't have been possible without the immense collaboration from my fellow researcher, Pranav K., whose expertise in machine learning greatly enriched our work and findings.\n\nRead the full paper here to discover how we are pushing the boundaries of prenatal care through technology.\nhttps://lnkd.in/dK7CvgVb\n\n#MachineLearning  #PrenatalCare #HealthcareInnovation #ResearchPublication\n#DataScience #HealthTech #AIinHealthcare #MedicalResearch #DigitalHealth #PregnancyCare #WomenInSTEM #TechForGood #PublicHealth",
        "location": "22\n              \n            \n      \n  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n            \n      \n        \n                2 Comments"
      }
    ],
    "similar_profiles": [],
    "recommendations": [],
    "publications": [
      {
        "name": "Dataset on density functional theory investigation of ternary Heusler alloys",
        "sub_title": "Data in Brief",
        "summary": "",
        "date": "February 2, 2024",
        "link": "https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Fdoi%2Eorg%2F10%2E1016%2Fj%2Edib%2E2023%2E109971&urlhash=2I8T&trk=public_profile_publication-title"
      }
    ],
    "courses": [],
    "languages": [],
    "organizations": [],
    "projects": [],
    "awards": [],
    "score": []
  }
]