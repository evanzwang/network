  Wrapper
    Main
        Banner
              PROJECTS
            WHAT WE'VE BEEN UP TO
              [F24 - S25](/projects/f24-s25)
              [F23 - S24](/projects/f23-s24)
              [F22 - S23](/projects/f22-s23)
              [F21 - S22](/projects/f21-s22)
              [F20 - S21](/projects/f20-s21)
              [F19 - S20](/projects/f19-s20)
              [F18 - S19](/projects/f18-s19)
              [S18](/projects/s18)
        Project List Builder
        Section
            SPRING 2024
              Gen-AI for Multi-Agent Deformable Object Manipulation
              Jonathan Ong
                *
                ,
        
        Zitong Huang
                ,
                Rida Faraz
                Vijay Kumaravelrajan
                Siddharth Rudharaju
                Anisha Chitta
                Daniel Seita
                Project Lead
                Project Advisor
              Robots hold great potential for automating tasks across various environments, yet their adoption is limited by their current capabilities, especially in complex scenarios like caregiving. To enhance automation and accessibility, this project works to advance robotic manipulation of objects that require multiple manipulators and deformable items such as bread and clothing. In this work, we integrate various robotic platforms, including ALOHA and Baxter, into the MuJoCo simulation environment using Robosuite, and set up bimanual configurations to explore different arm controllers. To robustly assess robotic performance, we identify specific tasks involving deformable objects and continuously refine our evaluation protocols.
                  [Poster](https://www.canva.com/design/DAF1mxXM5j4/j3Ka5dkVim1q-4FYeW4xzA/edit?utm_content=DAF1mxXM5j4&utm_campaign=designshare&utm_medium=link2&utm_source=sharebutton)
              Harmful Brain Activity Classification through EEG Spectrogram Data
              Jessica Fu
                Vayun Mathur
                Ryan Nene
                Brice Patchou
              Currently, electroencephalogram (EEG) monitoring heavily relies on manual analysis by specialized neurologists, leading to time-consuming and expensive procedures with potential errors. By applying deep learning techniques for EEG analysis, the Harmful Brain Activity Project strives to enhance the accuracy of electroencephalography pattern classification of harmful brain activities, such as seizures, to facilitate greater diagnoses and treatments for patients. By training convolutional neural networks (CNNs) in a specialized pipeline, we aim to create a highly effective model as a contribution towards AI applications in EEG analysis, thus positively impacting the preservation and advancement of human brain health.
                  [Slides](https://docs.google.com/presentation/d/1xrhAqk4LP2bnbUJZrILtj2ECVtaHzhzzoxRfzY2mGbM/edit?usp=sharing)
              CityLearn: Reducing Greenhouse Gas Emissions by Improving Energy Distribution via Time Series Forecasting
              Sanjana Ilango
                ,
        
        Spencer Tran
                Vidur Mushran
                Andrew Choi
                Joanne Lee
                Jimena Arce
              Buildings account for 30% of greenhouse gas emissions, making energy efficiency a critical focus for sustainability efforts. Distributed energy resources, such as domestic hot water systems that store electricity and solar panels that generate it, play a key role in alleviating the strain on building electric grids. To optimize the management and allocation of these resources across multiple buildings, it is essential to develop accurate and reliable energy usage predictions. This project aims to create robust predictive models that will enhance energy efficiency and contribute to reducing the environmental impact of buildings.
              Comparing Encoder-Decoder Architectures for Multimodal Hate Speech Detection in Hateful Memes Dataset
              Nathan Johnson
                Maohe (Mo) Jiang
                Jonathan Aydin
                Catherine Lu
                Darius Mahjoob
                Catherine He
              Multimodal hate speech detection presents additional challenges beyond unimodal detection, as subtle forms of hate speech often surface only when both text and images are analyzed together. This project examines the effectiveness and limitations of various pre-trained multimodal encoders in classifying content as hate speech. By comparing these models, we aim to identify the most viable approaches for accurately detecting hate speech in complex, multimodal contexts.
              Post-generation ASR Hypothesis Reranking Utilizing Visual Contexts (1.0)
              Youqi Huang
                ,
        
        Aryan Trehan
                Marcus Au
                Stan Loosmore
                Tommy Shu
                Yirui Song
              The Automatic Speech Recognition (ASR) pipeline proposed in "Multimodal Speech Recognition for Language-Guided Embodied Agents" (Chang et al.) processes both unimodal (audio-only) and multimodal (audiovisual) data to generate multiple ranked hypotheses based on a given ground truth statement. However, the model often fails to rank the hypothesis with the lowest Word Error Rate (WER) as the top choice. To address this issue, we propose a multimodal reranking pipeline that leverages the same visual cues used in the ASR process.
              Gender Workplace Bias in Large Language Models
              Rachita Jain
                Jessica Luna
                Kailin Xia
                Arjun Bedi
                Malina Freeman
              As large language models (LLMs) like ChatGPT gain prominence, addressing the biases embedded within these models is of paramount importance, particularly regarding gender and gender roles in the workplace. Historically, certain occupations have been linked with specific genders, resulting in significant imbalances across various sectors. To bridge this gender gap, it is essential that AI technologies do not perpetuate these biases. This project leverages LLaMA, a widely adopted open-source LLM, and employs prompt engineering techniques to investigate methods for reducing workplace gender bias in model responses. The objective is to ensure that LLMs exhibit gender neutrality, particularly in contexts characterized by ambiguity or uncertainty.
              Navigating Climate-Induced Turbulence: Optimizing Aviation Emissions Through Neural Network-Based Turbulence Detection (2.0)
              Jayne Bottarini
                ,
        
        Jaiv Doshi
                Pratyush Jaishanker
                Naina Panjwani
                Sanya Verma
                Lauren Sun
                Jay Campanell
                Sam Silva
              Aviation currently contributes to over 3% of global carbon dioxide emissions and will only contribute more as global travel levels increase [1], which is why implementing optimal flight paths based on emissions is essential. As the Earth warms, however, atmospheric wind patterns change unpredictably, inducing a cycle of more turbulent air, suboptimal flight paths, and increased emissions of carbon dioxide and other pollutants. We aim to contribute to breaking this cycle by employing generative and spatial machine learning techniques to downscale wind patterns in order to improve finer-scale wind speed predictions and inform emissions-based optimization techniques in flight paths.
              Computer Vision and Machine Learning on Optical Coherence Tomography for Middle Ear Pathology Detection (2.0)
              Claude Yoo
                ,
        
        Lucia Zhang
                Seena Pourzand
                Irika Katiyar
                Will Dolan
                Matthew Rodriguez
                Sana Jayaswal
                Brian Applegate
              Current diagnostic methods for middle ear diseases in otology are primarily qualitative and limited to examining only the surface of the tympanic membrane (TM). Optical Coherence Tomography (OCT) offers a non-invasive, quantitative imaging technique that enables three-dimensional reconstruction of the TM and middle ear, providing more detailed information than traditional methods. However, manually interpreting OCT scans can be time-consuming and challenging, and while OCT-based disease detection models are well-established in retinal imaging and ophthalmology, their application in otology remains relatively unexplored. This project focuses on creating a multi-classification machine learning model capable of identifying conditions such as retraction pockets, perforations, and cholesteatomas, and distinguishing them from healthy ear scans.
              Performance-based Feature Sampling for Reducing Bias in Image Recognition Models (2.0)
              Aarav Monga
                ,
        
        Sonia Zhang
                Advik Unni
                Shahzeb Lakhani
                Rajakrishnan Somou
                Antonio Ortega
              The presence of unseen bias in machine learning models remains a significant barrier to achieving trusted AI. While class imbalance is often addressed through training set sampling methods, this project targets a more nuanced challenge: bias within specific groups of a class. Such biases can create harmful, spurious correlations—like associating certain demographics with particular roles—that undermine the accuracy and fairness of representation learning. Addressing these issues involves a two-step process: first, identifying and labeling the bias groups, and second, adaptively sampling from these groups during training. This approach aims to correct the hidden biases that complicate model training and ultimately enhance the reliability of AI systems.
              Indigenous Language Translation with Sparse Data (4.0)
              Aryan Gulati
                ,
        
        Leslie Moreno
                Abhinav Gupta
                Aditya Kumar
                Jonathan May
              Imperialism has led to a loss of many indigenous cultures and with this, their languages. Based on the NeurIPS 2022 Competition “Second AmericasNLP Competition: Speech-to-Text Translation for Indigenous Languages of the Americas,” this project aims to use machine translation (MT) and automatic speech recognition (ASR) approaches to develop a translator for endangered or extinct indigenous languages. This will involve finding and/or building an appropriately sized corpus and using this to train MT and ASR models due to the sparsity of data on these indigenous languages.
            FALL 2023
              Navigating Climate-Induced Turbulence: Optimizing Aviation Emissions Through Neural Network-Based Turbulence Detection (1.0)
              Computer Vision and Machine Learning on Optical Coherence Tomography for Middle Ear Pathology Detection (1.0)
              Performance-based Feature Sampling for Reducing Bias in Image Recognition Models (1.0)
              Indigenous Language Translation with Sparse Data (3.0)
          [Next](/projects/f22-s23)
    Sidebar
        Menu
              CAIS++
              [About](/index)
              [Projects](/projects)
              People
                  [Current Members](/people)
                  [Alumni](/people/alumni)
                  [Invited Speakers](/curriculum/seminar)
              Curriculum
                  [Overview](/curriculum)
                  [[1] Introduction to AI](/curriculum/intro)
                  [2] Classical Machine Learning
                      [[2.1] k-Nearest Neighbors](/curriculum/classical/knn)
                      [[2.2] Linear Regression](/curriculum/classical/linear-regression)
                      [[2.3] Logistic Regression](/curriculum/classical/logistic-regression)
                      [[2.4] Support Vector Machines](/curriculum/classical/support-vector-machines)
                      [[2.5] Decision Trees](/curriculum/classical/decision-trees)
                      [[2.6] Naive Bayes](/curriculum/classical/naive-bayes)
                  [3] Neural Networks
                      [[3.1] Architecture](/curriculum/neural-networks/architecture)
                      [[3.2] Training](/curriculum/neural-networks/training)
                      [[3.3] Optimization](/curriculum/neural-networks/optimization)
                  [4] Neural Network Flavors
                      [[4.1] Convolutional Neural Networks](/curriculum/neural-network-flavors/convolutional-neural-networks)
                      [[4.2] Recurrent Neural Networks](/curriculum/neural-network-flavors/recurrent-neural-networks)
                      [[4.3] Attention & Transformers](/curriculum/neural-network-flavors/transformers)
                      [[4.4] Generative Adversarial Networks](/curriculum/neural-network-flavors/generative-adversarial-networks)
                [5] Special Topics
                    [[5.1] Transfer Learning](/curriculum/special-topics/transfer-learning)
                    [[5.2] Reinforcement Learning](/curriculum/special-topics/reinforcement-learning)
                  [Reading List](/curriculum/reading-list)
                  [Speaker Seminar](/curriculum/seminar)
              [Apply](/#applications)
              [Contact Us](/contact)
          <header class="major">
          <h2>Get in touch</h2>
          </header>
          <h3 class="nomargin">For Clients/Professors</h3>
          <p>Since our inception, our members have been striving to apply their skills in Artificial Intelligence to help solve the real problems in communities around us. Our student teams work with nonprofits, researchers, and community leaders on semester-long projects to ensure that new advancements in AI are used for social good.  At the moment, our projects are primarily centered around machine learning, a subfield of Artificial Intelligence that focuses on leveraging large amounts of data to build statistical models that are able to generate insights and predictions that traditional software can’t.</p>
          <a href="/contact/clients" class="button big">More Info</a>
          <h3>For Sponsors</h3>
          <p>The support of alumni, corporations, foundations, and individuals makes a real difference to the organization and our ability to make an impact.</p>
          <a href="/contact/sponsors" class="button big">More Info</a>
          <h3>For Prospective Members</h3>
          <p>We'd love to have you join our community! Please find our information on applying <a href='/#applications'>here</a>.</p>
          Contact Information
            <li class="icon solid fa-envelope"><a href="mailto:caisplus@usc.edu">caisplus@usc.edu</a></li>
            Our Sponsors
        Footer
          © CAIS++ Artificial Intelligence for social good.
            [HTML5 UP](https://html5up.net)
            .
  Scripts