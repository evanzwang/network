<!DOCTYPE html>
<html lang="en-US">

  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width,maximum-scale=2">
    <link rel="stylesheet" type="text/css" media="screen" href="/assets/css/style.css?v=">
    <link rel="shortcut icon" type="image/x-icon" href="favicon_io/favicon.ico">
<!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Algorithmic Alignment Group | Researching frameworks for human-aligned AI @ MIT CSAIL.</title>
<meta name="generator" content="Jekyll v4.3.4" />
<meta property="og:title" content="Algorithmic Alignment Group" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Researching frameworks for human-aligned AI @ MIT CSAIL." />
<meta property="og:description" content="Researching frameworks for human-aligned AI @ MIT CSAIL." />
<link rel="canonical" href="https://thestephencasper.github.io/team/" />
<meta property="og:url" content="https://thestephencasper.github.io/team/" />
<meta property="og:site_name" content="Algorithmic Alignment Group" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Algorithmic Alignment Group" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebPage","description":"Researching frameworks for human-aligned AI @ MIT CSAIL.","headline":"Algorithmic Alignment Group","url":"https://thestephencasper.github.io/team/"}</script>
<!-- End Jekyll SEO tag -->

    <!-- start custom head snippets, customize with your own _includes/head-custom.html file -->

<!-- Setup Google Analytics -->



<!-- You can set your favicon here -->
<!-- link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" -->

<!-- end custom head snippets -->

  </head>

  <body>

    <!-- HEADER -->
    <div id="header_wrap" class="outer">
        <header class="inner">
          

          <a href="/"><img style="float: left; padding-right: 20px; border: 0px;" src="/docs/assets/logo.png" width="68" height="68"></a><h1 id="project_title">Algorithmic Alignment Group</h1>
          <h3 id="project_tagline">Researching frameworks for human-aligned AI @ MIT CSAIL.</h3>

          
        </header>
    </div>

    <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">
        
<!--<h1>Group Name and Logo</h1>-->

<!--<head>-->
<!--    <meta charset="utf-8">-->
<!--    <link rel="stylesheet" href="_includes/styles.css">-->
<!--</head>-->

<center>
    <nav>
        <ul class="nav__links">
            <li><a href="/"><h3>Home</h3></a></li>
            <li><a href="/team/"><h3>Team</h3></a></li>
            <li><a href="/research/"><h3>Research</h3></a></li>
            <li><a href="/contact/"><h3>Contact</h3></a></li>
        </ul>
    </nav>
</center>

<h2 id="team">Team</h2>

<!--<img src="/docs/assets/sillhouette.jpeg" width="160" height="160" alt="Person 1 Name"> <p>Person 1, person1@gmail.com, website link<br>Bio goes here.</p>-->

<h3>Principal Investigator</h3>

<p>
    <img style="padding-right: 15px;" src="/docs/assets/dhm.png" width="160" height="160" alt="Dylan Hadfield-Menell" />
    <strong>Dylan Hadfield-Menell</strong>, dhm[at]csail[dot]mit[dot]edu, <a href="http://people.csail.mit.edu/dhm/">Website</a>
    <br />
    Dylan is an assistant professor on the faculty of Artificial Intelligence and Decision-Making in the EECS Department and Computer Science and Artificial Intelligence Laboratory (CSAIL) at the Massachusetts Institute of Technology (MIT). His research focuses on the problem of agent alignment: the challenge of identifying behaviors that are consistent with the goals of another actor or group of actors. His work aims to identify algorithmic solutions to alignment problems that arise from groups of AI systems, principal-agent pairs (i.e., human-robot teams), and societal oversight of ML systems.
</p>

<h3>Postdoctoral Researchers</h3>

<p>
    <img style="padding-right: 15px;" src="/docs/assets/rakshit_image.jpg" width="160" height="160" alt="Rakshit S. Trivedi" />
    <strong>Rakshit S. Trivedi</strong>, rstrivedi[at]csail[dot]mit[dot]edu, <a href="https://www.rtrivedi.me/">Website</a>
    <br />
    Rakshit is a Postdoctoral Associate in the Computer Science and Artificial Intelligence Laboratory (CSAIL) at MIT. Prior to that, he was a Postdoctoral Fellow in EconCS at Harvard School of Engineering and Applied Sciences (SEAS) working on multi-agent reinforcement learning and imitation learning for economic design. He obtained his PhD from Georgia Institute of Technology, focusing on machine learning for networked and multi-agent systems. He is broadly interested in the development of AI capable of learning from human experiences, can quickly adapt to evolving human needs, and achieve alignment with human values. Through the lens of multi-agent reinforcement learning, he is interested in studying the effectiveness of such AI in the presence of social, economic and cultural factors.
</p>

<h3>Research Scientists</h3>

<p>
    <img style="padding-right: 15px;" src="/docs/assets/pinar.png" width="160" height="160" alt="A. Pinar Ozisik" />
    <strong>A. Pinar Ozisik</strong>, pinaro[at]mit[dot]edu, <a href="https://pinaro.github.io/">Website</a>
    <br />
    Pinar is a research scientist, broadly interested in ensuring that algorithms and systems behave safely, correctly, and in line with their intended purpose in the real world. Before joining the team, Pinar was a visiting researcher in the MIT Media Lab with the Camera Culture group. She received her Ph.D. from the University of Massachusetts Amherst, where she focused on the analysis and application of concentration inequalities to preserve the desirable properties of systems.
</p>

<h3>Ph.D Students</h3>

<p>
    <img style="padding-right: 15px;" src="/docs/assets/aruna.png" width="160" height="160" alt="Aruna Sankaranarayanan" />
    <strong>Aruna Sankaranarayanan</strong>, arunas[at]mit[dot]edu, <a href="https://www.linkedin.com/in/arunasank/">Linkedin</a>
    <br />
    Aruna is a PhD student interested in using interpretability methods to explain model and human behaviours. Her work utilizes causal interpretability methods to encourage model safety. Her past work has included understanding how humans interface with AI generated content, as well as audits of black box social media algorithms. She loves free and open source software, Tamil Bhakti poetry, and giant trees.
</p>

<p>
    <img style="padding-right: 15px;" src="/docs/assets/pjkc.jpg" width="160" height="160" alt="Phillip Christoffersen" />
    <strong>Phillip Christoffersen</strong>, philljkc[at]mit[dot]edu, <a href="http://people.csail.mit.edu/philljkc/">Website</a>
    <br />
    Phillip is broadly interested in reinforcement learning topics including AI alignment, neurosymbolic AI, and multi-agent RL. Before the Algorithmic Alignment Group, Phillip was an undergraduate researcher at the University of Toronto, advised by Prof. Sheila McIlraith. His main hobbies include reading, playing piano, and composing music.
</p>

<p>
    <img style="padding-right: 15px;" src="/docs/assets/rachelm8.jpeg" width="160" height="160" alt="Rachel Ma" />
    <strong>Rachel Ma</strong>, rachelm8[at]mit[dot]edu, <a href="https://rachelma80000.github.io/index.html">Website</a>
    <br />
    Rachel is interested in decision-making for alignment to human preferences, collaborative teaming and interactions between humans and autonomous agents/systems for personalization while maintaining generalization. She works within a mix of NLP, vision, and robotics. Before her PhD, she double majored in Computer Science and Music at Brown University and did robotics+NLP research advised by George Konidaris and Stefanie Tellex. Her hobbies include playing piano, composing, watching movies, and spending time with friends.
</p>

<p>
    <img style="padding-right: 15px;" src="/docs/assets/cas.png" width="160" height="160" alt="Stephen Casper" />
    <strong>Stephen Casper</strong>, scasper[at]mit[dot]edu, <a href="https://stephencasper.com">Website</a>
    <br />
    Cas works on a lot of miscellaneous things, but most of his work focuses on red-teaming, robustness, and evaluations/audits. Before his Ph.D, he worked with the Harvard Kreiman Lab and the Center for Human-Compatible AI. Hobbies of his include biking, growing plants, and keeping insects.
</p>

<p>
    <img style="padding-right: 15px;" src="/docs/assets/stewy_2022.jpeg" width="160" height="160" alt="Stewart Slocum" />
    <strong>Stewart Slocum</strong>, sslocum3[at]mit[dot]edu, <a href="https://www.stewyslocum.com/">Website</a>
    <br />
    Stewart’s research interests center on aligning AI systems — such as reinforcement learning systems and large language models — with human goals. He is also interested in the theoretical foundations of alignment and the intersection of machine learning and causality. Outside of work, he enjoys playing piano, backpacking, salsa dancing, and philosophy.
</p>

<h3>Masters Students</h3>

<p>
    <img style="padding-right: 15px;" src="/docs/assets/adriano.png" width="160" height="160" alt="Adriano Hernandez" />
    <strong>Adriano Hernandez</strong>, adrianoh[at]mit[dot]edu, <a href="https://www.linkedin.com/in/adriano-hernandez/">LinkedIn</a>
    <br />
    As a large language model, Adriano is passionate about interpretability and the science of deep learning. His current work focuses on using insights from activation engineering to improve the robustness of language models such as himself to data poisoning attacks. Previously, he was first engineer at Meru, where he built retrieval augmented generation systems for document-based question-answering.
</p>

<p>
    <img style="padding-right: 15px;" src="/docs/assets/ariba.png" width="160" height="160" alt="Ariba Khan" />
    <strong>Ariba Khan</strong>, akhan02[at]mit[dot]edu
    <br />
    Ariba is a Master of Engineering (MEng) student who is researching cultural bias and cultural alignment of Large Language Models (LLMs). Her academic interests extend to AI fairness, model debiasing, and interpretability. In her free time, Ariba enjoys listening to music, visiting art museums, and reading historical fiction novels.
</p>

<p>
    <img style="padding-right: 15px;" src="/docs/assets/timmy.jpg" width="160" height="160" alt="Timothy Qian" />
    <strong>Timothy Qian</strong>, tcqian[at]mit[dot]edu, <a href="https://linkedin.com/in/12tqian">LinkedIn</a>
    <br />
    Timothy is a Master of Engineering (MEng) student focused on red-teaming, robustness, and preference learning for language models. Before joining the Algorithmic Alignment Group, he conducted research in quantum information theory and proximal operators.
</p>

<!--<h3>Interns and UROPs</h3>-->

<!--<p>-->
<!--    <img style="padding-right: 15px;" src="/docs/assets/jessica.jpg" width="160" height="160" alt="Jessica Turner">-->
<!--    <strong>Jessica Turner</strong>, jturner3[at]umbc[dot]edu, <a href="https://www.linkedin.com/in/jessica-turner-3353561b1/">LinkedIn</a>-->
<!--    <br>-->
<!--    Jessica is a member of the class of 2024 at the University of Maryland, Baltimore County (UMBC) with a major of computer science. Her interests lie in Human Computer Interaction research, teaching, as well as playing (piano/guitar) and listening to RnB and soul music.-->
<!--</p>-->

<!--<p>-->
<!--    <img style="padding-right: 15px;" src="/docs/assets/Lennart.JPG" width="160" height="160" alt="Lennart Schulze">-->
<!--    <strong>Lennart Schulze</strong>, ls3932[at]columbia[dot]edu, <a href="https://www.linkedin.com/in/lennart-schulze/">LinkedIn</a>-->
<!--    <br>-->
<!--    Lennart’s research aims to promote safe and aligned AI through methods for explainability as well as adversarial robustness of machine learning models. In addition, he works in the Creative Machines Lab on robot perception and self-modeling via neural-implicit 3d vision. He currently finishes his master’s degree in computer science at Columbia University after having worked as research assistant at IBM Research.-->
<!--</p>-->

<h3>Former Students</h3>

<p>
    <img style="padding-right: 15px;" src="/docs/assets/andreas2.png" width="160" height="160" alt="Andreas Haupt" />
    <strong>Andreas Haupt</strong>, haupt[at]csail[dot]mit[dot]edu, <a href="http://www.andyhaupt.com/">Website</a>
    <br />
    Andy is a postdoctoral fellow at Stanford University's <a href="https://hai.stanford.edu/fellows">Institute for Human-Centered AI</a> where he researches Artificial Intelligence and the economic impacts of its deployment. He completed his Ph.D. in Engineering-Economic Systems in 2024, and is the first Ph.D. student of the Algorithmic Alignment group.
</p>

<p>
    <img style="padding-right: 15px;" src="/docs/assets/deepika.jpeg" width="160" height="160" alt="Deepika Raman" />
    <strong>Deepika Raman</strong>, deepikar[at]mit[dot]edu, <a href="https://www.linkedin.com/in/deepikaraman/">LinkedIn</a>
    <br />
    Deepika is a graduate student in MIT’s Technology and Policy Program. Her research interests lie in the responsible and equitable design of emerging technologies and public digital goods. Currently, she is working on participatory approaches to AI across the development lifecycle and challenges with their governance. Previously, Deepika worked with the University of Chicago Trust, India - leading teams tackling data governance, digital transformation, and AI policy at the Ministry of Electronics and IT, Government of India.
</p>

<p>
    <img style="padding-right: 15px;" src="/docs/assets/eunseo.jpeg" width="160" height="160" alt="Dana Choi" />
    <strong>Dana Choi</strong>, choie[at]mit[dot]edu
    <br />
    Dana is broadly interested in understanding how the human normative system works and what enables cooperation. Through reverse-engineering the mechanisms of human collective intelligence, she hopes to contribute to efforts in designing and facilitating desirable interactions in our society. She draws insights from economics, anthropology, cognitive science, reinforcement learning, and social computing.
</p>

<p>
    <img style="padding-right: 15px;" src="/docs/assets/hendrik.png" width="160" height="160" alt="Hendrik Mayer" />
    <strong>Hendrik Mayer</strong>, hmayer[at]mit[dot]edu
    <br />
    Hendrik is a Master of Engineering (MEng) student working on theoretical alignment problems in reinforcement learning systems. Before joining the Algorithmic Alignment Group, he researched topics in algebraic complexity theory with Prof. Markus Bläser and worked in the Emergent Quantum Matter Group at MIT. His hobbies include playing soccer and hiking.
</p>

<p>
    <img style="padding-right: 15px;" src="/docs/assets/julian.jpg" width="160" height="160" alt="Julian Manyika" />
    <strong>Julian Manyika</strong>, jmanyika[at]mit[dot]edu, <a href="https://www.linkedin.com/in/julianmanyika444/">LinkedIn</a>
    <br />
    Julian is a Masters in Engineering (MEng) student working on alignment for Large Language Models. Julian’s interests include reward-modeling on reasoning, evaluating language model understanding of human conversation and intent, and the possibility for AI research to help inform the way we think about morality.
</p>

<p>
    <img style="padding-right: 15px;" src="/docs/assets/prajna.png" width="160" height="160" alt="Prajna Soni" />
    <strong>Prajna Soni</strong>, prajna[at]mit[dot]edu, <a href="https://www.linkedin.com/in/prajnasoni/">LinkedIn</a>
    <br />
    Prajna is an S.M. student in the Technology and Policy Program and EECS. Her research interests are broadly in the evaluation of algorithmic systems, both from a technical and regulatory perspective, algorithmic fairness and tools which facilitate the development of safer and more trustworthy AI. Prior to MIT, Prajna graduated from NYU Abu Dhabi in 2020 and was awarded the Post-graduate Research Fellow at NYU Abu Dhabi where she investigated bias propagation in recommender systems.
</p>

<p>
    <img style="padding-right: 15px;" src="/docs/assets/taylor.png" width="160" height="160" alt="Taylor Curtis" />
    <strong>Taylor Lynn Curtis</strong>, tlcurtis[at]mit[dot]edu, <a href="https://www.linkedin.com/in/taylor-lynn-curtis-650746142/">LinkedIn</a>
    <br />
    Taylor Lynn is an S.M. candidate in technology and policy. Prior to her current degree, she obtained a bachelor of software engineering with a minor in political science from McGill University in Montréal, Canada. Her research interests include the effectiveness of governance surrounding large, generative models, quantifying the societal impact of AI, and more generally the regulatory frameworks that function in the technology space.
</p>

<p>
    <img style="padding-right: 15px;" src="/docs/assets/tim.jpeg" width="160" height="160" alt="Timothy Kostolansky" />
    <strong>Timothy Kostolandky</strong>, timkosto[at]mit[dot]edu, <a href="https://tim0120.github.io/">Website</a>
    <br />
    Tim is a Master of Engineering student interested in improving the safety of AI systems, specifically through the lens of interpretability. Before his MEng, Tim double-majored in computer science and physics at MIT. Outside of work, Tim enjoys playing sports, reading, and meditating.
</p>

<p>
    <img style="padding-right: 15px;" src="/docs/assets/Mehul.jpeg" width="160" height="160" alt="Mehul Damani" />
    <strong>Mehul Damani</strong>, mehul42[at]mit[dot]edu, <a href="https://damanimehul.github.io/">Website</a>
    <br />
    Mehul’s research broadly aims to improve multi-agent reinforcement learning systems using techniques and ideas from model-based RL, intrinsic motivation, curriculum learning, and reward design. Prior to joining MIT, he worked on developing general-purpose curriculum learning methods for reinforcement learning agents and on applying reinforcement learning to domains such as multi-agent pathfinding and multi-agent traffic signal control. His hobbies include reading and playing soccer.
</p>

<p>
    <img style="padding-right: 15px;" src="/docs/assets/olivia.jpg" width="160" height="160" alt="Olivia Siegel" />
    <strong>Olivia Siegel</strong>, osiegel[at]mit[dot]edu, <a href="https://www.linkedin.com/in/olivia-siegel/">LinkedIn</a>
    <br />
    Olivia is a masters student interested in AI and robotics who gets most excited seeing algorithms come to life on physical robots. Prior to joining the Algorithmic Alignment group, she did her undergraduate at MIT in EECS and worked on soft robots in the Distributed Robotics Lab. Like any good New Englander, her hobbies include shellfishing, cycling, and maple syrup making.
</p>

<p>
    <img style="padding-right: 15px;" src="/docs/assets/rjy2.jpeg" width="160" height="160" alt="Rui-Jie Yew" />
    <strong>Rui-Jie Yew</strong>, rjy[at]mit[dot]edu, <a href="https://r-jy.github.io/">Website</a>
    <br />
    Rui-Jie is an S.M. student in Technology and Policy. Her research interests are in the human-centered and legal aspects of computation, both in the design of regulation for emerging technologies as well as in the operationalization of legal values for technical systems. In 2021, she received a joint B.A. in computer science and mathematics from Scripps College as an off-campus student at Harvey Mudd College.
</p>

<p>
    <img style="padding-right: 15px;" src="/docs/assets/jovana.jpg" width="160" height="160" alt="Jovana Kondic" />
    <strong>Jovana Kondic</strong>, jkondic[at]mit[dot]edu, <a href="https://www.linkedin.com/in/jovanakondic/">LinkedIn</a>
    <br />
    Jovana's interests lie broadly at the intersection of probabilistic inference, social cognition, and human-robot interaction. Her research focuses on building interactive AI agents that 1) effectively learn from human input, and 2) understand and act in accordance with human preferences, intentions, and values.
</p>

<p>
    <img style="padding-right: 15px;" src="/docs/assets/lena.png" width="160" height="160" alt="Magdalena Price" />
    <strong>Magdalena Price</strong>, maprice[at]mit[dot]edu
    <br />
    Lena is a first-year M-Eng student whose research focuses on human-computer interfaces and machine learning. Her current project is focused on making effective data preparation scalable and inexpensive, in the hopes of mitigating biased model results commonly seen in big data predictions.
</p>

<p>
    <img style="padding-right: 15px;" src="/docs/assets/max.png" width="160" height="160" alt="Max Langenkamp" />
    <strong>Max Langenkamp</strong>, maxnz[at]mit[dot]]edu
    <br />
    Max is researching AI governance. His current focus is on open source machine learning software and how it shapes AI research. He is especially inspired by the work of economist Elinor Ostrom and draws from fields ranging from the philosophy of science to the economics of innovation. Previously, he has researched computational cognitive science, worked at the White House Office of Science and Technology Policy, and published on AI policy at the Center for Security and Emerging Technology. He has a B.A. from MIT in computer science and loves bossa nova, Tibetan mythology and the history of technology.
</p>

<!--<br>-->
<!--<h4>Undergraduate Students</h4>-->


      </section>
    </div>

    <!-- FOOTER  -->
    <div id="footer_wrap" class="outer">
      <footer class="inner">
<!--        -->
<!--        <p>Published with <a href="https://pages.github.com">GitHub Pages</a></p>-->
      </footer>
    </div>
  </body>
</html>